{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"chuvas_jp_2123-08.csv\", usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:57:12</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@qbrunito Se você perceber os jurados todos es...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:13:07</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>Tudo que eu queria agora era uma chuva beeeeee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:01:39</td>\n",
       "      <td>João Pessoa - PB</td>\n",
       "      <td>@JapaArtes @CorreiosBR @jairbolsonaro Essa mer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 16:53:34</td>\n",
       "      <td>João Pessoa, Brazil</td>\n",
       "      <td>E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 16:26:59</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@xicosa @fabi2moraes Foi chuva, mas essa chuva...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                local  \\\n",
       "0  2020-08-22 20:57:12  João Pessoa, Brasil   \n",
       "1  2020-08-22 20:13:07  João Pessoa, Brasil   \n",
       "2  2020-08-22 20:01:39     João Pessoa - PB   \n",
       "3  2020-08-22 16:53:34  João Pessoa, Brazil   \n",
       "4  2020-08-22 16:26:59  João Pessoa, Brasil   \n",
       "\n",
       "                                               texto  relevancia  \n",
       "0  @qbrunito Se você perceber os jurados todos es...           0  \n",
       "1  Tudo que eu queria agora era uma chuva beeeeee...           0  \n",
       "2  @JapaArtes @CorreiosBR @jairbolsonaro Essa mer...           0  \n",
       "3  E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...           0  \n",
       "4  @xicosa @fabi2moraes Foi chuva, mas essa chuva...           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:57:12</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@qbrunito Se você perceber os jurados todos es...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:13:07</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>Tudo que eu queria agora era uma chuva beeeeee...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:01:39</td>\n",
       "      <td>João Pessoa - PB</td>\n",
       "      <td>@JapaArtes @CorreiosBR @jairbolsonaro Essa mer...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 16:53:34</td>\n",
       "      <td>João Pessoa, Brazil</td>\n",
       "      <td>E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 16:26:59</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@xicosa @fabi2moraes Foi chuva, mas essa chuva...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                local  \\\n",
       "0  2020-08-22 20:57:12  João Pessoa, Brasil   \n",
       "1  2020-08-22 20:13:07  João Pessoa, Brasil   \n",
       "2  2020-08-22 20:01:39     João Pessoa - PB   \n",
       "3  2020-08-22 16:53:34  João Pessoa, Brazil   \n",
       "4  2020-08-22 16:26:59  João Pessoa, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  @qbrunito Se você perceber os jurados todos es...           0    JP  \n",
       "1  Tudo que eu queria agora era uma chuva beeeeee...           0    JP  \n",
       "2  @JapaArtes @CorreiosBR @jairbolsonaro Essa mer...           0    JP  \n",
       "3  E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...           0    JP  \n",
       "4  @xicosa @fabi2moraes Foi chuva, mas essa chuva...           0    JP  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sigla'] = 'JP'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al = pd.read_csv('chuvas_al_1822-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 19:53:38</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>@Enaldinho1 @uselolja @QGDoEnaldinho Chuva #MP...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 18:30:26</td>\n",
       "      <td>𝒂𝒕𝒂𝒍𝒂𝒊𝒂</td>\n",
       "      <td>\"– Hayden. O nome dele será Hayden.\"\\n(Chuva -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 18:16:59</td>\n",
       "      <td>𝒂𝒕𝒂𝒍𝒂𝒊𝒂</td>\n",
       "      <td>Ainda tô no prólogo de Chuva e já senti vontad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 18:16:13</td>\n",
       "      <td>𝒂𝒕𝒂𝒍𝒂𝒊𝒂</td>\n",
       "      <td>\"Ela soluçava ruidosamente. Era um choro parti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 17:49:46</td>\n",
       "      <td>𝒂𝒕𝒂𝒍𝒂𝒊𝒂</td>\n",
       "      <td>\"A chuva estava quase chegando.\"\\n(Chuva - Liv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario     local  \\\n",
       "0  2020-08-22 19:53:38  Alagoas    \n",
       "1  2020-08-22 18:30:26   𝒂𝒕𝒂𝒍𝒂𝒊𝒂   \n",
       "2  2020-08-22 18:16:59   𝒂𝒕𝒂𝒍𝒂𝒊𝒂   \n",
       "3  2020-08-22 18:16:13   𝒂𝒕𝒂𝒍𝒂𝒊𝒂   \n",
       "4  2020-08-22 17:49:46   𝒂𝒕𝒂𝒍𝒂𝒊𝒂   \n",
       "\n",
       "                                               texto  relevancia  \n",
       "0  @Enaldinho1 @uselolja @QGDoEnaldinho Chuva #MP...           0  \n",
       "1  \"– Hayden. O nome dele será Hayden.\"\\n(Chuva -...           0  \n",
       "2  Ainda tô no prólogo de Chuva e já senti vontad...           0  \n",
       "3  \"Ela soluçava ruidosamente. Era um choro parti...           0  \n",
       "4  \"A chuva estava quase chegando.\"\\n(Chuva - Liv...           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_al.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_al['Sigla'] = 'AL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df,df_al])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:57:12</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@qbrunito Se você perceber os jurados todos es...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:13:07</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>Tudo que eu queria agora era uma chuva beeeeee...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:01:39</td>\n",
       "      <td>João Pessoa - PB</td>\n",
       "      <td>@JapaArtes @CorreiosBR @jairbolsonaro Essa mer...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 16:53:34</td>\n",
       "      <td>João Pessoa, Brazil</td>\n",
       "      <td>E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 16:26:59</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@xicosa @fabi2moraes Foi chuva, mas essa chuva...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2020-08-18 14:59:36</td>\n",
       "      <td>Maceió, Brasil</td>\n",
       "      <td>eu odeio n ter condições de criar outro cachor...</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-08-18 12:34:05</td>\n",
       "      <td>Alagoas🌵</td>\n",
       "      <td>Chuva de arroz??? https://t.co/3RhcvW0M4h</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-08-18 09:57:46</td>\n",
       "      <td>Maceió, Brasil</td>\n",
       "      <td>@lenycatia @ThRod @correio Imagina 57mil pesso...</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-08-18 09:43:29</td>\n",
       "      <td>Alagoas, Brazil</td>\n",
       "      <td>a chuva da vitoria vai reinar no fim 🌈🌈🌈🌈🌈🌈🌈🌈</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-08-18 09:36:26</td>\n",
       "      <td>Ibirama, Brasil</td>\n",
       "      <td>RT @tehlopess: @IrlanLopess Ainda colocou baru...</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                horario                local  \\\n",
       "0   2020-08-22 20:57:12  João Pessoa, Brasil   \n",
       "1   2020-08-22 20:13:07  João Pessoa, Brasil   \n",
       "2   2020-08-22 20:01:39     João Pessoa - PB   \n",
       "3   2020-08-22 16:53:34  João Pessoa, Brazil   \n",
       "4   2020-08-22 16:26:59  João Pessoa, Brasil   \n",
       "..                  ...                  ...   \n",
       "95  2020-08-18 14:59:36       Maceió, Brasil   \n",
       "96  2020-08-18 12:34:05             Alagoas🌵   \n",
       "97  2020-08-18 09:57:46       Maceió, Brasil   \n",
       "98  2020-08-18 09:43:29      Alagoas, Brazil   \n",
       "99  2020-08-18 09:36:26      Ibirama, Brasil   \n",
       "\n",
       "                                                texto  relevancia Sigla  \n",
       "0   @qbrunito Se você perceber os jurados todos es...           0    JP  \n",
       "1   Tudo que eu queria agora era uma chuva beeeeee...           0    JP  \n",
       "2   @JapaArtes @CorreiosBR @jairbolsonaro Essa mer...           0    JP  \n",
       "3   E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...           0    JP  \n",
       "4   @xicosa @fabi2moraes Foi chuva, mas essa chuva...           0    JP  \n",
       "..                                                ...         ...   ...  \n",
       "95  eu odeio n ter condições de criar outro cachor...           0    AL  \n",
       "96          Chuva de arroz??? https://t.co/3RhcvW0M4h           0    AL  \n",
       "97  @lenycatia @ThRod @correio Imagina 57mil pesso...           0    AL  \n",
       "98      a chuva da vitoria vai reinar no fim 🌈🌈🌈🌈🌈🌈🌈🌈           0    AL  \n",
       "99  RT @tehlopess: @IrlanLopess Ainda colocou baru...           0    AL  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am = pd.read_csv('chuvas_am_22-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_am['Sigla'] = 'AM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:48:03</td>\n",
       "      <td>Manaus, Brasil</td>\n",
       "      <td>RT @cigarctic: ventou, ventou, ventou e nenhum...</td>\n",
       "      <td>0</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:39:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @vitrrhugo: quando chove em manaus https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:38:49</td>\n",
       "      <td>Manaus, Brasil</td>\n",
       "      <td>@tiagotheworld Amo q ela levou chuva de unf ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 20:03:03</td>\n",
       "      <td>Manaus, Brasil</td>\n",
       "      <td>@dunburnt Pior que eu fui olhar agora e tá com...</td>\n",
       "      <td>0</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 19:46:21</td>\n",
       "      <td>Manaus</td>\n",
       "      <td>RT @vitrrhugo: quando chove em manaus https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario            local  \\\n",
       "0  2020-08-22 20:48:03  Manaus, Brasil    \n",
       "1  2020-08-22 20:39:24              NaN   \n",
       "2  2020-08-22 20:38:49   Manaus, Brasil   \n",
       "3  2020-08-22 20:03:03   Manaus, Brasil   \n",
       "4  2020-08-22 19:46:21           Manaus   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  RT @cigarctic: ventou, ventou, ventou e nenhum...           0    AM  \n",
       "1  RT @vitrrhugo: quando chove em manaus https://...           0    AM  \n",
       "2  @tiagotheworld Amo q ela levou chuva de unf ma...           0    AM  \n",
       "3  @dunburnt Pior que eu fui olhar agora e tá com...           0    AM  \n",
       "4  RT @vitrrhugo: quando chove em manaus https://...           0    AM  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_am.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JP    100\n",
       "AL    100\n",
       "AM    100\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_am])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba= pd.read_csv('chuvas_ba_2021-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba['Sigla'] = 'BA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-21 20:57:24</td>\n",
       "      <td>salvador bahia</td>\n",
       "      <td>@LuciaLo20914588 🤣🤣🤣 vdd!\\nMorei em Belém, cho...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21 20:50:01</td>\n",
       "      <td>Salvador, Brasil</td>\n",
       "      <td>Que conversa é essa que vcs querem neve aqui e...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-21 20:34:33</td>\n",
       "      <td>Salvador</td>\n",
       "      <td>Toda vez que chove eu oro pedindo a Deus que p...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-21 20:19:56</td>\n",
       "      <td>João Pessoa/PB</td>\n",
       "      <td>RT @jrmutti: @MarquinhosAssu2 @simpraisa Morei...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-21 20:04:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @MarcilioJuniior: Sexta feira, frio do cara...</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario             local  \\\n",
       "0  2020-08-21 20:57:24    salvador bahia   \n",
       "1  2020-08-21 20:50:01  Salvador, Brasil   \n",
       "2  2020-08-21 20:34:33          Salvador   \n",
       "3  2020-08-21 20:19:56    João Pessoa/PB   \n",
       "4  2020-08-21 20:04:13               NaN   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  @LuciaLo20914588 🤣🤣🤣 vdd!\\nMorei em Belém, cho...           0    BA  \n",
       "1  Que conversa é essa que vcs querem neve aqui e...           0    BA  \n",
       "2  Toda vez que chove eu oro pedindo a Deus que p...           0    BA  \n",
       "3  RT @jrmutti: @MarquinhosAssu2 @simpraisa Morei...           0    BA  \n",
       "4  RT @MarcilioJuniior: Sexta feira, frio do cara...           0    BA  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BA    100\n",
       "JP    100\n",
       "AL    100\n",
       "AM    100\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_ba])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ce = pd.read_csv('chuvas_ce_22-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ce['Sigla'] = 'CE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:58:44</td>\n",
       "      <td>Fortaleza, Brasil</td>\n",
       "      <td>@jacksoncruz A chuva dos 200 espirros</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:44:18</td>\n",
       "      <td>Ceará</td>\n",
       "      <td>a unica certeza q tenho eh q qdo abrir o insta...</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:43:48</td>\n",
       "      <td>Ceará</td>\n",
       "      <td>@Marisaaloppes aproveita a chuva marisinha vc ...</td>\n",
       "      <td>0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 20:29:17</td>\n",
       "      <td>Ceará, Brazil</td>\n",
       "      <td>do nada uma chuva em sobral??</td>\n",
       "      <td>1</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 20:28:10</td>\n",
       "      <td>Ceará, Brasil</td>\n",
       "      <td>CHUVA REAL EM SOBRAL EM AGOSTO PQP</td>\n",
       "      <td>1</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario              local  \\\n",
       "0  2020-08-22 20:58:44  Fortaleza, Brasil   \n",
       "1  2020-08-22 20:44:18              Ceará   \n",
       "2  2020-08-22 20:43:48              Ceará   \n",
       "3  2020-08-22 20:29:17      Ceará, Brazil   \n",
       "4  2020-08-22 20:28:10      Ceará, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0              @jacksoncruz A chuva dos 200 espirros           0    CE  \n",
       "1  a unica certeza q tenho eh q qdo abrir o insta...           0    CE  \n",
       "2  @Marisaaloppes aproveita a chuva marisinha vc ...           0    CE  \n",
       "3                      do nada uma chuva em sobral??           1    CE  \n",
       "4                 CHUVA REAL EM SOBRAL EM AGOSTO PQP           1    CE  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CE    100\n",
       "BA    100\n",
       "JP    100\n",
       "AL    100\n",
       "AM    100\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_ce])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cg = pd.read_csv('chuvas_cg_1723-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cg['Sigla'] = 'CG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 11:03:59</td>\n",
       "      <td>Campina Grande- Paraíba</td>\n",
       "      <td>santa chuva é foda, triste dms</td>\n",
       "      <td>0</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 02:54:42</td>\n",
       "      <td>Campina Grande, Brasil</td>\n",
       "      <td>@carlalarrat @loranmoreira_ eu quero chuva, co...</td>\n",
       "      <td>0</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-21 22:23:54</td>\n",
       "      <td>Campina Grande</td>\n",
       "      <td>@YagoCostat rapaz a brisa não pode ver chuva kkk</td>\n",
       "      <td>0</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-21 21:28:11</td>\n",
       "      <td>Campina Grande, Brasil</td>\n",
       "      <td>E essa chuva ein??? 💢🖤\\n\\n#SuperLiveVascoTV</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-21 21:22:21</td>\n",
       "      <td>Campina Grande-Paraíba</td>\n",
       "      <td>\"Vou por a \"FOTO de minha CIDADE\" aqui pra vcs...</td>\n",
       "      <td>0</td>\n",
       "      <td>CG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                    local  \\\n",
       "0  2020-08-22 11:03:59  Campina Grande- Paraíba   \n",
       "1  2020-08-22 02:54:42   Campina Grande, Brasil   \n",
       "2  2020-08-21 22:23:54           Campina Grande   \n",
       "3  2020-08-21 21:28:11   Campina Grande, Brasil   \n",
       "4  2020-08-21 21:22:21   Campina Grande-Paraíba   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0                     santa chuva é foda, triste dms           0    CG  \n",
       "1  @carlalarrat @loranmoreira_ eu quero chuva, co...           0    CG  \n",
       "2   @YagoCostat rapaz a brisa não pode ver chuva kkk           0    CG  \n",
       "3        E essa chuva ein??? 💢🖤\\n\\n#SuperLiveVascoTV           1    CG  \n",
       "4  \"Vou por a \"FOTO de minha CIDADE\" aqui pra vcs...           0    CG  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CE    100\n",
       "BA    100\n",
       "JP    100\n",
       "AL    100\n",
       "AM    100\n",
       "CG     33\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_cg])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mt = pd.read_csv('chuvas_mt_2022-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mt['Sigla'] = 'MT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:59:17</td>\n",
       "      <td>Cuiabá, Brasil</td>\n",
       "      <td>RT @henricre: @bofumaporro so fumo maconha qua...</td>\n",
       "      <td>0</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 19:00:24</td>\n",
       "      <td>Cuiabá, Brasil</td>\n",
       "      <td>@bofumaporro so fumo maconha quando chove e qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 16:48:14</td>\n",
       "      <td>Cuiabá, Brasil</td>\n",
       "      <td>bolinho de chuva eh tão bom</td>\n",
       "      <td>0</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 14:05:26</td>\n",
       "      <td>Cuiabá, Brasil</td>\n",
       "      <td>eu no carnaval proucurando a leticia na porra ...</td>\n",
       "      <td>0</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 13:22:26</td>\n",
       "      <td>Cuiabá, Brasil</td>\n",
       "      <td>Meu pai tá tão enjoado de fica em casa que na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario           local  \\\n",
       "0  2020-08-22 20:59:17  Cuiabá, Brasil   \n",
       "1  2020-08-22 19:00:24  Cuiabá, Brasil   \n",
       "2  2020-08-22 16:48:14  Cuiabá, Brasil   \n",
       "3  2020-08-22 14:05:26  Cuiabá, Brasil   \n",
       "4  2020-08-22 13:22:26  Cuiabá, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  RT @henricre: @bofumaporro so fumo maconha qua...           0    MT  \n",
       "1  @bofumaporro so fumo maconha quando chove e qu...           0    MT  \n",
       "2                        bolinho de chuva eh tão bom           0    MT  \n",
       "3  eu no carnaval proucurando a leticia na porra ...           0    MT  \n",
       "4  Meu pai tá tão enjoado de fica em casa que na ...           0    MT  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT    100\n",
       "CE    100\n",
       "BA    100\n",
       "JP    100\n",
       "AL    100\n",
       "AM    100\n",
       "CG     33\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_mt])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pa= pd.read_csv('chuvas_pa_22-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pa['Sigla'] = 'PA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:52:33</td>\n",
       "      <td>Belém, Brasil</td>\n",
       "      <td>RT @cassioffaial: Em Belém não chega nem a chu...</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:50:59</td>\n",
       "      <td>Belém, Brasil</td>\n",
       "      <td>RT @cassioffaial: Em Belém não chega nem a chu...</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:50:27</td>\n",
       "      <td>Pará, Brasil</td>\n",
       "      <td>A chuva de hoje foi tão boa❤❤</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 20:29:19</td>\n",
       "      <td>Belém</td>\n",
       "      <td>Ouvindo anunciação e lembrando dele\\n\\nchove c...</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 20:20:10</td>\n",
       "      <td>Belém, Brasil</td>\n",
       "      <td>RT @cassioffaial: Em Belém não chega nem a chu...</td>\n",
       "      <td>0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario          local  \\\n",
       "0  2020-08-22 20:52:33  Belém, Brasil   \n",
       "1  2020-08-22 20:50:59  Belém, Brasil   \n",
       "2  2020-08-22 20:50:27   Pará, Brasil   \n",
       "3  2020-08-22 20:29:19         Belém    \n",
       "4  2020-08-22 20:20:10  Belém, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  RT @cassioffaial: Em Belém não chega nem a chu...           0    PA  \n",
       "1  RT @cassioffaial: Em Belém não chega nem a chu...           0    PA  \n",
       "2                      A chuva de hoje foi tão boa❤❤           0    PA  \n",
       "3  Ouvindo anunciação e lembrando dele\\n\\nchove c...           0    PA  \n",
       "4  RT @cassioffaial: Em Belém não chega nem a chu...           0    PA  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT    100\n",
       "CE    100\n",
       "AL    100\n",
       "AM    100\n",
       "PA    100\n",
       "BA    100\n",
       "JP    100\n",
       "CG     33\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_pa])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe = pd.read_csv('chuvas_pe_22-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pe['Sigla'] = 'PE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:59:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @LorranPhelipe: Como posso desejar chuva e ...</td>\n",
       "      <td>0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:39:07</td>\n",
       "      <td>Guanambi, Brasil</td>\n",
       "      <td>RT @LorranPhelipe: Como posso desejar chuva e ...</td>\n",
       "      <td>0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:34:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @LorranPhelipe: Como posso desejar chuva e ...</td>\n",
       "      <td>0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 20:28:20</td>\n",
       "      <td>Recife,PE</td>\n",
       "      <td>@TiagoAraujo___ Eu fui guerreira e fui na chuv...</td>\n",
       "      <td>0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 20:18:40</td>\n",
       "      <td>Recife, Brasil</td>\n",
       "      <td>Já silenciei os grupos do trabalho. Já comprei...</td>\n",
       "      <td>0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario             local  \\\n",
       "0  2020-08-22 20:59:40               NaN   \n",
       "1  2020-08-22 20:39:07  Guanambi, Brasil   \n",
       "2  2020-08-22 20:34:32               NaN   \n",
       "3  2020-08-22 20:28:20         Recife,PE   \n",
       "4  2020-08-22 20:18:40    Recife, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  RT @LorranPhelipe: Como posso desejar chuva e ...           0    PE  \n",
       "1  RT @LorranPhelipe: Como posso desejar chuva e ...           0    PE  \n",
       "2  RT @LorranPhelipe: Como posso desejar chuva e ...           0    PE  \n",
       "3  @TiagoAraujo___ Eu fui guerreira e fui na chuv...           0    PE  \n",
       "4  Já silenciei os grupos do trabalho. Já comprei...           0    PE  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT    100\n",
       "CE    100\n",
       "AL    100\n",
       "AM    100\n",
       "PA    100\n",
       "PE    100\n",
       "BA    100\n",
       "JP    100\n",
       "CG     33\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_pe])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rj= pd.read_csv('chuvas_rj_22-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rj['Sigla'] = 'RJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:59:10</td>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>eu quero a chuva que me prometeram</td>\n",
       "      <td>0</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:58:52</td>\n",
       "      <td>Cuiabá, Brasil</td>\n",
       "      <td>RT @guilhermesousa: Queria aqui agradecer ao j...</td>\n",
       "      <td>0</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:58:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @niquefds: Graças a Deus o tempo melhora am...</td>\n",
       "      <td>0</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 20:58:10</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Chuva chata do crlho 🤦‍♂️</td>\n",
       "      <td>1</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 20:57:37</td>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>RT @djxande_: Pandemia + chuva = quem não tem ...</td>\n",
       "      <td>0</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                   local  \\\n",
       "0  2020-08-22 20:59:10  Rio de Janeiro, Brasil   \n",
       "1  2020-08-22 20:58:52          Cuiabá, Brasil   \n",
       "2  2020-08-22 20:58:41                     NaN   \n",
       "3  2020-08-22 20:58:10         Rio de Janeiro    \n",
       "4  2020-08-22 20:57:37  Rio de Janeiro, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0                 eu quero a chuva que me prometeram           0    RJ  \n",
       "1  RT @guilhermesousa: Queria aqui agradecer ao j...           0    RJ  \n",
       "2  RT @niquefds: Graças a Deus o tempo melhora am...           0    RJ  \n",
       "3                          Chuva chata do crlho 🤦‍♂️           1    RJ  \n",
       "4  RT @djxande_: Pandemia + chuva = quem não tem ...           0    RJ  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT    100\n",
       "CE    100\n",
       "AL    100\n",
       "AM    100\n",
       "PA    100\n",
       "PE    100\n",
       "BA    100\n",
       "JP    100\n",
       "RJ    100\n",
       "CG     33\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_rj])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp = pd.read_csv('chuvas_sp_21-08.csv', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['Sigla'] = 'SP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-21 20:59:35</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>RT @tricovotweets: Ontem, às 20h00, Paulinho B...</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21 20:58:21</td>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>RT @barbaradzz: do que adianta essa friaca e e...</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-21 20:57:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @rebs_rebeca: Esse tempo frio com chuva me ...</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-21 20:56:02</td>\n",
       "      <td>São Bernardo do Campo, Brasil</td>\n",
       "      <td>@AmandaAlvesB_ Melhor pegar ônibus na chuva e ...</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-21 20:53:43</td>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>@goulart_lenita Aqui, litoral sul de sp, 9 gra...</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                          local  \\\n",
       "0  2020-08-21 20:59:35                         Brasil   \n",
       "1  2020-08-21 20:58:21              São Paulo, Brasil   \n",
       "2  2020-08-21 20:57:31                            NaN   \n",
       "3  2020-08-21 20:56:02  São Bernardo do Campo, Brasil   \n",
       "4  2020-08-21 20:53:43              São Paulo, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  RT @tricovotweets: Ontem, às 20h00, Paulinho B...           0    SP  \n",
       "1  RT @barbaradzz: do que adianta essa friaca e e...           1    SP  \n",
       "2  RT @rebs_rebeca: Esse tempo frio com chuva me ...           0    SP  \n",
       "3  @AmandaAlvesB_ Melhor pegar ônibus na chuva e ...           0    SP  \n",
       "4  @goulart_lenita Aqui, litoral sul de sp, 9 gra...           1    SP  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT    100\n",
       "CE    100\n",
       "SP    100\n",
       "AL    100\n",
       "AM    100\n",
       "PA    100\n",
       "PE    100\n",
       "BA    100\n",
       "JP    100\n",
       "RJ    100\n",
       "CG     33\n",
       "Name: Sigla, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_final, df_sp])\n",
    "df_final['Sigla'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Análise__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:57:12</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@qbrunito Se você perceber os jurados todos es...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:13:07</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>Tudo que eu queria agora era uma chuva beeeeee...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:01:39</td>\n",
       "      <td>João Pessoa - PB</td>\n",
       "      <td>@JapaArtes @CorreiosBR @jairbolsonaro Essa mer...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 16:53:34</td>\n",
       "      <td>João Pessoa, Brazil</td>\n",
       "      <td>E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 16:26:59</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>@xicosa @fabi2moraes Foi chuva, mas essa chuva...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                local  \\\n",
       "0  2020-08-22 20:57:12  João Pessoa, Brasil   \n",
       "1  2020-08-22 20:13:07  João Pessoa, Brasil   \n",
       "2  2020-08-22 20:01:39     João Pessoa - PB   \n",
       "3  2020-08-22 16:53:34  João Pessoa, Brazil   \n",
       "4  2020-08-22 16:26:59  João Pessoa, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0  @qbrunito Se você perceber os jurados todos es...           0    JP  \n",
       "1  Tudo que eu queria agora era uma chuva beeeeee...           0    JP  \n",
       "2  @JapaArtes @CorreiosBR @jairbolsonaro Essa mer...           0    JP  \n",
       "3  E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...           0    JP  \n",
       "4  @xicosa @fabi2moraes Foi chuva, mas essa chuva...           0    JP  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_final.csv', usecols=[1,2,3,4,5])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1033 entries, 0 to 1032\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   horario     1033 non-null   object\n",
      " 1   local       946 non-null    object\n",
      " 2   texto       1033 non-null   object\n",
      " 3   relevancia  1033 non-null   int64 \n",
      " 4   Sigla       1033 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 40.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('texto', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 884 entries, 0 to 1032\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   horario     884 non-null    object\n",
      " 1   local       844 non-null    object\n",
      " 2   texto       884 non-null    object\n",
      " 3   relevancia  884 non-null    int64 \n",
      " 4   Sigla       884 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 41.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @qbrunito Se você perceber os jurados todos es...\n",
       "1    Tudo que eu queria agora era uma chuva beeeeee...\n",
       "2    @JapaArtes @CorreiosBR @jairbolsonaro Essa mer...\n",
       "3    E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...\n",
       "4    @xicosa @fabi2moraes Foi chuva, mas essa chuva...\n",
       "5    @amana_chuva Claro. E provavelmente vai sair t...\n",
       "6                                   @amana_chuva Foda!\n",
       "7                   @amana_chuva Véi esse disco ♥️♥️♥️\n",
       "8       @tellmeylm Chuva THALITA MENEGHIM NO MULTISHOW\n",
       "9    c meu prato de miojo c creme de leite depois d...\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['texto'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@qbrunito Se você perceber os jurados todos estão cantando músicas em Português e no primeiro dia o Jarbas tbm cantou o cantando na chuva na versão brasileira, então está muito mais para um reflexo sobre como é o público jovem de musicais, que acha que apenas em inglês is good\n",
      "Tudo que eu queria agora era uma chuva beeeeeeeemmmmm forte pelo resto da noite.\n",
      "@JapaArtes @CorreiosBR @jairbolsonaro Essa merda já era pra estar privatizada, serviço porco e caro, Sedex chega a custar mais caro a outros serviços e demora mais. Estraviam produtos, danificam, aqui em casa já jogaram a encomenda por cima do portão, certa vez pegou chuva molhou tudo. Privatiza tudo...\n",
      "E  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mostra evidências e fatos claros, mais eles ciscam e esperneiam, tentando invalidar isso com a \"chuva de dislikes\" - que mostra o quão ridículo e raso é o pensamento dessa gente\n",
      "+\n",
      "@xicosa @fabi2moraes Foi chuva, mas essa chuva não aconteceria se não fosse para salvar o Nordeste, há uma ideia de mercado no Instituto de Metereologia, que chuva no Nordeste é ruim para o turismo.\n",
      "@amana_chuva Claro. E provavelmente vai sair todo “sentido” depois das críticas que está recebendo\n",
      "@amana_chuva Foda!\n",
      "@amana_chuva Véi esse disco ♥️♥️♥️\n",
      "@tellmeylm Chuva THALITA MENEGHIM NO MULTISHOW\n",
      "c meu prato de miojo c creme de leite depois de uma manhã cansativa debaixo de chuva, quero guerra c ninguém.  😴\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "6    None\n",
       "7    None\n",
       "8    None\n",
       "9    None\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['texto'][0:10].apply(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando links e menções\n",
    "\n",
    "import emoji\n",
    "#tokenizer = nltk.load\n",
    "\n",
    "def limpaString(strOriginal):\n",
    "    \n",
    "    limpaMencao = re.sub('@[A-Za-z0-9_]+', '', strOriginal) \n",
    "    limpaTags = re.sub('#', '', limpaMencao) \n",
    "    limpaLinks = re.sub('\\w+:\\/\\/\\S+','', limpaTags)\n",
    "    limpaPontuacao = re.sub('[-.,;:!?_()*+=\"%$]+','',limpaLinks)\n",
    "    limpaEmojis = emoji.get_emoji_regexp().sub('', limpaPontuacao)\n",
    "    removeNumeros = re.sub('[0-9]', '', limpaEmojis)\n",
    "    final = removeNumeros.lower()\n",
    "    \n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "strTeste = df['texto'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tudo que eu queria agora era uma chuva beeeeeeeemmmmm forte pelo resto da noite.'"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strTeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tudo que eu queria agora era uma chuva beeeeeeeemmmmm forte pelo resto da noite'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strLimpa = limpaString(strTeste)\n",
    "strLimpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo = df.copy()\n",
    "df_limpo['texto'] = df_limpo['texto'].apply(limpaString) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horario</th>\n",
       "      <th>local</th>\n",
       "      <th>texto</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Sigla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22 20:57:12</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>se você perceber os jurados todos estão canta...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-22 20:13:07</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>tudo que eu queria agora era uma chuva beeeeee...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-22 20:01:39</td>\n",
       "      <td>João Pessoa - PB</td>\n",
       "      <td>essa merda já era pra estar privatizada ser...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-22 16:53:34</td>\n",
       "      <td>João Pessoa, Brazil</td>\n",
       "      <td>e  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-22 16:26:59</td>\n",
       "      <td>João Pessoa, Brasil</td>\n",
       "      <td>foi chuva mas essa chuva não aconteceria se ...</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               horario                local  \\\n",
       "0  2020-08-22 20:57:12  João Pessoa, Brasil   \n",
       "1  2020-08-22 20:13:07  João Pessoa, Brasil   \n",
       "2  2020-08-22 20:01:39     João Pessoa - PB   \n",
       "3  2020-08-22 16:53:34  João Pessoa, Brazil   \n",
       "4  2020-08-22 16:26:59  João Pessoa, Brasil   \n",
       "\n",
       "                                               texto  relevancia Sigla  \n",
       "0   se você perceber os jurados todos estão canta...           0    JP  \n",
       "1  tudo que eu queria agora era uma chuva beeeeee...           0    JP  \n",
       "2     essa merda já era pra estar privatizada ser...           0    JP  \n",
       "3  e  ̶p̶a̶r̶e̶c̶e̶ ̶q̶u̶e̶ ̶ quanto mais você mo...           0    JP  \n",
       "4    foi chuva mas essa chuva não aconteceria se ...           0    JP  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    580\n",
       "1    304\n",
       "Name: relevancia, dtype: int64"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpo['relevancia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sigla  relevancia\n",
       "AL     0             73\n",
       "       1             26\n",
       "AM     0             52\n",
       "       1             22\n",
       "BA     0             69\n",
       "       1             25\n",
       "CE     0             64\n",
       "       1             21\n",
       "CG     0             22\n",
       "       1             11\n",
       "JP     1             56\n",
       "       0             40\n",
       "MT     0             78\n",
       "       1             18\n",
       "PA     0             50\n",
       "       1             41\n",
       "PE     1             45\n",
       "       0             40\n",
       "RJ     0             49\n",
       "       1             17\n",
       "SP     0             43\n",
       "       1             22\n",
       "Name: relevancia, dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpo.groupby('Sigla')['relevancia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sigla,relevancia'>"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_limpo.groupby('Sigla')['relevancia'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevancia\n",
       "0    580\n",
       "1    304\n",
       "Name: texto, dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limpo.groupby('relevancia')['texto'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = df_limpo[df_limpo['relevancia']==1]['texto'].values\n",
    "irrel = df_limpo[df_limpo['relevancia']==0]['texto'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tamanho_medio(strEntrada):\n",
    "    \n",
    "    valor = 0\n",
    "    for strE in strEntrada:\n",
    "        valor+= len(strE.split())\n",
    "    return (valor/len(strEntrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Méida de palavras (tweets relevantes): 11.572368421052632\n",
      "Méida de palavras (tweets irrelevantes): 17.355172413793102\n"
     ]
    }
   ],
   "source": [
    "print('Méida de palavras (tweets relevantes): {}'.format(tamanho_medio(rel)))\n",
    "print('Méida de palavras (tweets irrelevantes): {}'.format(tamanho_medio(irrel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeTweets(strEntrada):\n",
    "    \n",
    "    strToken=\"\"\n",
    "    for strE in strEntrada:\n",
    "        strToken += strE\n",
    "    return word_tokenize(strToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaNgram(strEntrada, num):\n",
    "    \n",
    "    token = tokenizeTweets(strEntrada)\n",
    "    cont = Counter(ngrams(token,num))    \n",
    "    if num==1:\n",
    "        cont = {key[0]:value for key, value in cont.items()}\n",
    "    return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = contaNgram(rel,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unigramas = [(key, value) for (key, value) in sorted(cont.items(),reverse=True, key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chuva', 215),\n",
       " ('de', 133),\n",
       " ('e', 107),\n",
       " ('a', 76),\n",
       " ('que', 63),\n",
       " ('em', 54),\n",
       " ('do', 52),\n",
       " ('o', 45),\n",
       " ('com', 45),\n",
       " ('eu', 42),\n",
       " ('pra', 41),\n",
       " ('é', 41),\n",
       " ('essa', 39),\n",
       " ('da', 36),\n",
       " ('um', 32),\n",
       " ('não', 31),\n",
       " ('no', 29),\n",
       " ('na', 29),\n",
       " ('frio', 28),\n",
       " ('chove', 27),\n",
       " ('só', 20),\n",
       " ('tá', 20),\n",
       " ('aqui', 17),\n",
       " ('mas', 17),\n",
       " ('se', 17),\n",
       " ('uma', 17),\n",
       " ('deus', 14),\n",
       " ('por', 14),\n",
       " ('já', 13),\n",
       " ('dia', 13)]"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigramas[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = contaNgram(rel, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramas = [(key, value) for (key, value) in sorted(cont.items(),reverse=True, key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('essa', 'chuva'), 29),\n",
       " (('de', 'chuva'), 29),\n",
       " (('a', 'chuva'), 22),\n",
       " (('chuva', 'e'), 17),\n",
       " (('com', 'chuva'), 11),\n",
       " (('chuva', 'do'), 11),\n",
       " (('e', 'a'), 9),\n",
       " (('chuva', 'em'), 8),\n",
       " (('chuva', 'de'), 7),\n",
       " (('da', 'chuva'), 7),\n",
       " (('e', 'essa'), 7),\n",
       " (('chuva', 'é'), 7),\n",
       " (('na', 'chuva'), 7),\n",
       " (('uma', 'chuva'), 7),\n",
       " (('e', 'eu'), 7),\n",
       " (('chuva', 'mas'), 6),\n",
       " (('chuva', 'da'), 6),\n",
       " (('nessa', 'chuva'), 5),\n",
       " (('que', 'eu'), 5),\n",
       " (('do', 'nada'), 5)]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramas[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = contaNgram(rel, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramas = [(key, value) for (key, value) in sorted(cont.items(),reverse=True, key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('e', 'essa', 'chuva'), 7),\n",
       " (('de', 'chuva', 'e'), 4),\n",
       " (('chuva', 'da', 'porra'), 4),\n",
       " (('que', 'deus', 'proteja'), 3),\n",
       " (('deus', 'proteja', 'os'), 3),\n",
       " (('chuva', 'do', 'nada'), 3),\n",
       " (('essa', 'chuva', 'do'), 3),\n",
       " (('e', 'eu', 'aqui'), 3),\n",
       " (('chuva', 'do', 'caju'), 3),\n",
       " (('cheirinho', 'de', 'chuva'), 3),\n",
       " (('proteja', 'os', 'motoboys'), 2),\n",
       " (('os', 'motoboys', 'nessa'), 2),\n",
       " (('motoboys', 'nessa', 'chuva'), 2),\n",
       " (('de', 'chuva', 'bom'), 2),\n",
       " (('bom', 'pra', 'ficar'), 2),\n",
       " (('e', 'a', 'internet'), 2),\n",
       " (('a', 'chuva', 'mas'), 2),\n",
       " (('dias', 'de', 'chuva'), 2),\n",
       " (('chuva', 'vento', 'e'), 2),\n",
       " (('vento', 'e', 'frio'), 2)]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramas[:20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokenizeTweets(rel)\n",
    "\n",
    "buscaBigramas = nltk.collocations.BigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bigramas = nltk.collocations.BigramAssocMeasures()\n",
    "bigramasPMI = buscaBigramas.score_ngrams(bigramas.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "buscaTrigramas = nltk.collocations.TrigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramas = nltk.collocations.TrigramAssocMeasures()\n",
    "trigramasPMI = buscaTrigramas.score_ngrams(trigramas.pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __TF - IDF__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "completo = df_limpo['texto'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cont = contaNgram(completo,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unigramas = [(key, value) for (key, value) in sorted(cont.items(),reverse=True, key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chuva', 678),\n",
       " ('de', 525),\n",
       " ('e', 374),\n",
       " ('a', 332),\n",
       " ('que', 307),\n",
       " ('o', 249),\n",
       " ('é', 181),\n",
       " ('em', 164),\n",
       " ('eu', 160),\n",
       " ('do', 154),\n",
       " ('não', 150),\n",
       " ('na', 144),\n",
       " ('com', 139),\n",
       " ('pra', 133),\n",
       " ('da', 125),\n",
       " ('no', 123),\n",
       " ('um', 120),\n",
       " ('frio', 114),\n",
       " ('uma', 109),\n",
       " ('só', 84),\n",
       " ('chove', 81),\n",
       " ('se', 72),\n",
       " ('essa', 71),\n",
       " ('mas', 70),\n",
       " ('mais', 69),\n",
       " ('aqui', 67),\n",
       " ('tá', 66),\n",
       " ('quando', 60),\n",
       " ('me', 60),\n",
       " ('por', 56),\n",
       " ('tem', 54),\n",
       " ('para', 50),\n",
       " ('q', 50),\n",
       " ('vai', 48),\n",
       " ('já', 47),\n",
       " ('nem', 45),\n",
       " ('os', 44),\n",
       " ('as', 43),\n",
       " ('esse', 42),\n",
       " ('sem', 41),\n",
       " ('foi', 39),\n",
       " ('minha', 39),\n",
       " ('dia', 37),\n",
       " ('meu', 37),\n",
       " ('hoje', 37),\n",
       " ('como', 36),\n",
       " ('até', 36),\n",
       " ('tempo', 33),\n",
       " ('ou', 33),\n",
       " ('gente', 32),\n",
       " ('pq', 32),\n",
       " ('agora', 31),\n",
       " ('sol', 31),\n",
       " ('deus', 31),\n",
       " ('casa', 30),\n",
       " ('rt', 30),\n",
       " ('nada', 29),\n",
       " ('todo', 27),\n",
       " ('mesmo', 27),\n",
       " ('aí', 27),\n",
       " ('tudo', 26),\n",
       " ('ser', 26),\n",
       " ('muito', 23),\n",
       " ('era', 22),\n",
       " ('isso', 22),\n",
       " ('pode', 22),\n",
       " ('dias', 22),\n",
       " ('toda', 22),\n",
       " ('depois', 21),\n",
       " ('bem', 21),\n",
       " ('você', 20),\n",
       " ('vez', 20),\n",
       " ('sair', 20),\n",
       " ('n', 20),\n",
       " ('faz', 20),\n",
       " ('vida', 20),\n",
       " ('vou', 20),\n",
       " ('nunca', 20),\n",
       " ('ano', 20),\n",
       " ('calor', 20),\n",
       " ('pelo', 19),\n",
       " ('ao', 19),\n",
       " ('tava', 19),\n",
       " ('rua', 19),\n",
       " ('vem', 19),\n",
       " ('nessa', 18),\n",
       " ('está', 17),\n",
       " ('queria', 17),\n",
       " ('ainda', 17),\n",
       " ('pessoas', 17),\n",
       " ('ficar', 17),\n",
       " ('manaus', 17),\n",
       " ('noite', 16),\n",
       " ('ir', 16),\n",
       " ('bom', 16),\n",
       " ('cair', 16),\n",
       " ('porra', 16),\n",
       " ('quero', 15),\n",
       " ('to', 15),\n",
       " ('lá', 15),\n",
       " ('cai', 15),\n",
       " ('hj', 15),\n",
       " ('neve', 15),\n",
       " ('menos', 15),\n",
       " ('pela', 15),\n",
       " ('chuvas', 15),\n",
       " ('dessa', 14),\n",
       " ('“', 14),\n",
       " ('”', 14),\n",
       " ('cidade', 14),\n",
       " ('ela', 14),\n",
       " ('nos', 14),\n",
       " ('pessoa', 14),\n",
       " ('né', 14),\n",
       " ('tu', 14),\n",
       " ('vento', 14),\n",
       " ('muita', 14),\n",
       " ('tão', 14),\n",
       " ('sim', 14),\n",
       " ('quem', 14),\n",
       " ('°c', 14),\n",
       " ('cara', 14),\n",
       " ('assim', 14),\n",
       " ('ele', 14),\n",
       " ('forte', 13),\n",
       " ('chega', 13),\n",
       " ('c', 13),\n",
       " ('chegou', 13),\n",
       " ('p', 13),\n",
       " ('amo', 13),\n",
       " ('temperatura', 13),\n",
       " ('semana', 13),\n",
       " ('nesse', 13),\n",
       " ('mundo', 13),\n",
       " ('céu', 13),\n",
       " ('dormir', 12),\n",
       " ('ter', 12),\n",
       " ('msm', 12),\n",
       " ('melhor', 12),\n",
       " ('hora', 12),\n",
       " ('clima', 12),\n",
       " ('ta', 12),\n",
       " ('filme', 12),\n",
       " ('chover', 12),\n",
       " ('fica', 12),\n",
       " ('guarda', 12),\n",
       " ('°', 12),\n",
       " ('dos', 12),\n",
       " ('vezes', 11),\n",
       " ('caiu', 11),\n",
       " ('tô', 11),\n",
       " ('anos', 11),\n",
       " ('passar', 11),\n",
       " ('ia', 11),\n",
       " ('fui', 11),\n",
       " ('sua', 11),\n",
       " ('caralho', 11),\n",
       " ('deixa', 11),\n",
       " ('carro', 11),\n",
       " ('sei', 11),\n",
       " ('belém', 11),\n",
       " ('fazer', 11),\n",
       " ('praia', 10),\n",
       " ('antes', 10),\n",
       " ('parasita', 10),\n",
       " ('viu', 10),\n",
       " ('pois', 10),\n",
       " ('banho', 10),\n",
       " ('barulho', 10),\n",
       " ('sabe', 10),\n",
       " ('uns', 10),\n",
       " ('te', 10),\n",
       " ('ver', 10),\n",
       " ('fora', 10),\n",
       " ('salvador', 10),\n",
       " ('onde', 10),\n",
       " ('cuiabá', 10),\n",
       " ('todos', 9),\n",
       " ('então', 9),\n",
       " ('sobre', 9),\n",
       " ('nordeste', 9),\n",
       " ('há', 9),\n",
       " ('odeio', 9),\n",
       " ('sempre', 9),\n",
       " ('previsão', 9),\n",
       " ('pouco', 9),\n",
       " ('fria', 9),\n",
       " ('boa', 9),\n",
       " ('pro', 9),\n",
       " ('ontem', 9),\n",
       " ('são', 9),\n",
       " ('será', 9),\n",
       " ('coisa', 9),\n",
       " ('época', 9),\n",
       " ('vc', 9),\n",
       " ('veio', 9),\n",
       " ('pegar', 9),\n",
       " ('sábado', 9),\n",
       " ('olha', 9),\n",
       " ('dar', 9),\n",
       " ('das', 8),\n",
       " ('debaixo', 8),\n",
       " ('lugar', 8),\n",
       " ('tirar', 8),\n",
       " ('falando', 8),\n",
       " ('causa', 8),\n",
       " ('fico', 8),\n",
       " ('senhor', 8),\n",
       " ('sul', 8),\n",
       " ('cama', 8),\n",
       " ('internet', 8),\n",
       " ('ar', 8),\n",
       " ('nao', 8),\n",
       " ('gosta', 8),\n",
       " ('num', 8),\n",
       " ('quente', 8),\n",
       " ('meses', 8),\n",
       " ('meio', 8),\n",
       " ('dentro', 8),\n",
       " ('jogo', 8),\n",
       " ('à', 8),\n",
       " ('pior', 8),\n",
       " ('seu', 8),\n",
       " ('sensação', 8),\n",
       " ('acho', 8),\n",
       " ('mt', 8),\n",
       " ('pandemia', 8),\n",
       " ('estão', 7),\n",
       " ('tbm', 7),\n",
       " ('ruim', 7),\n",
       " ('manhã', 7),\n",
       " ('ninguém', 7),\n",
       " ('correr', 7),\n",
       " ('h', 7),\n",
       " ('medo', 7),\n",
       " ('pensando', 7),\n",
       " ('mim', 7),\n",
       " ('for', 7),\n",
       " ('vontade', 7),\n",
       " ('vi', 7),\n",
       " ('tarde', 7),\n",
       " ('teto', 7),\n",
       " ('porque', 7),\n",
       " ('deu', 7),\n",
       " ('granizo', 7),\n",
       " ('tenho', 7),\n",
       " ('água', 7),\n",
       " ('kkk', 7),\n",
       " ('ai', 7),\n",
       " ('pai', 7),\n",
       " ('tomar', 7),\n",
       " ('numa', 7),\n",
       " ('demais', 7),\n",
       " ('galera', 7),\n",
       " ('finalmente', 7),\n",
       " ('desde', 7),\n",
       " ('aq', 7),\n",
       " ('chegar', 7),\n",
       " ('nós', 7),\n",
       " ('raios', 7),\n",
       " ('recife', 7),\n",
       " ('caju', 7),\n",
       " ('maior', 7),\n",
       " ('acha', 6),\n",
       " ('cima', 6),\n",
       " ('quanto', 6),\n",
       " ('fosse', 6),\n",
       " ('foda', 6),\n",
       " ('mil', 6),\n",
       " ('enfim', 6),\n",
       " ('momento', 6),\n",
       " ('chuvart', 6),\n",
       " ('som', 6),\n",
       " ('chovendo', 6),\n",
       " ('carai', 6),\n",
       " ('logo', 6),\n",
       " ('olhar', 6),\n",
       " ('paz', 6),\n",
       " ('vamos', 6),\n",
       " ('feliz', 6),\n",
       " ('duas', 6),\n",
       " ('tanto', 6),\n",
       " ('pedir', 6),\n",
       " ('parece', 6),\n",
       " ('cedo', 6),\n",
       " ('estou', 6),\n",
       " ('amiga', 6),\n",
       " ('diz', 6),\n",
       " ('estava', 6),\n",
       " ('quase', 6),\n",
       " ('trabalhar', 6),\n",
       " ('baixo', 6),\n",
       " ('inverno', 6),\n",
       " ('etc', 6),\n",
       " ('povo', 6),\n",
       " ('molhado', 6),\n",
       " ('dois', 6),\n",
       " ('outro', 6),\n",
       " ('teve', 6),\n",
       " ('imagina', 6),\n",
       " ('cada', 6),\n",
       " ('favor', 6),\n",
       " ('vcs', 6),\n",
       " ('esperando', 6),\n",
       " ('kkkkkkkkkk', 6),\n",
       " ('primeira', 6),\n",
       " ('amanhã', 6),\n",
       " ('deve', 6),\n",
       " ('igual', 6),\n",
       " ('ºc', 6),\n",
       " ('blá', 6),\n",
       " ('apenas', 5),\n",
       " ('estar', 5),\n",
       " ('dando', 5),\n",
       " ('conta', 5),\n",
       " ('roupas', 5),\n",
       " ('qualquer', 5),\n",
       " ('às', 5),\n",
       " ('dps', 5),\n",
       " ('algum', 5),\n",
       " ('vejo', 5),\n",
       " ('molha', 5),\n",
       " ('celular', 5),\n",
       " ('tinha', 5),\n",
       " ('pé', 5),\n",
       " ('pensar', 5),\n",
       " ('lembro', 5),\n",
       " ('joão', 5),\n",
       " ('outras', 5),\n",
       " ('coisas', 5),\n",
       " ('difícil', 5),\n",
       " ('brasil', 5),\n",
       " ('sinal', 5),\n",
       " ('graus', 5),\n",
       " ('chuvachuva', 5),\n",
       " ('parar', 5),\n",
       " ('tomei', 5),\n",
       " ('livro', 5),\n",
       " ('tal', 5),\n",
       " ('viver', 5),\n",
       " ('triste', 5),\n",
       " ('dizer', 5),\n",
       " ('inferno', 5),\n",
       " ('choveu', 5),\n",
       " ('seca', 5),\n",
       " ('sentindo', 5),\n",
       " ('cabeça', 5),\n",
       " ('alegria', 5),\n",
       " ('nosso', 5),\n",
       " ('livros', 5),\n",
       " ('após', 5),\n",
       " ('verão', 5),\n",
       " ('umas', 5),\n",
       " ('frente', 5),\n",
       " ('térmica', 5),\n",
       " ('andar', 5),\n",
       " ('ficou', 5),\n",
       " ('vendo', 5),\n",
       " ('quer', 5),\n",
       " ('castigo', 5),\n",
       " ('luta', 5),\n",
       " ('lavar', 5),\n",
       " ('cabelo', 5),\n",
       " ('fez', 5),\n",
       " ('estamos', 5),\n",
       " ('gramado', 5),\n",
       " ('tipo', 5),\n",
       " ('recebi', 5),\n",
       " ('minutos', 5),\n",
       " ('real', 5),\n",
       " ('pqp', 5),\n",
       " ('bolinho', 5),\n",
       " ('verdade', 5),\n",
       " ('gosto', 5),\n",
       " ('pega', 5),\n",
       " ('fumaça', 5),\n",
       " ('música', 5),\n",
       " ('primeiro', 4),\n",
       " ('público', 4),\n",
       " ('merda', 4),\n",
       " ('caro', 4),\n",
       " ('eles', 4),\n",
       " ('volta', 4),\n",
       " ('principalmente', 4),\n",
       " ('festa', 4),\n",
       " ('fiquei', 4),\n",
       " ('deles', 4),\n",
       " ('rolê', 4),\n",
       " ('saco', 4),\n",
       " ('amém', 4),\n",
       " ('proteja', 4),\n",
       " ('moto', 4),\n",
       " ('oq', 4),\n",
       " ('kkkkkk', 4),\n",
       " ('esses', 4),\n",
       " ('assistir', 4),\n",
       " ('embora', 4),\n",
       " ('centro', 4),\n",
       " ('bate', 4),\n",
       " ('roupa', 4),\n",
       " ('novo', 4),\n",
       " ('preguiça', 4),\n",
       " ('aquela', 4),\n",
       " ('esquece', 4),\n",
       " ('nariz', 4),\n",
       " ('saiu', 4),\n",
       " ('minhas', 4),\n",
       " ('achei', 4),\n",
       " ('so', 4),\n",
       " ('massa', 4),\n",
       " ('terra', 4),\n",
       " ('realidade', 4),\n",
       " ('chata', 4),\n",
       " ('amg', 4),\n",
       " ('tristeza', 4),\n",
       " ('the', 4),\n",
       " ('mpn', 4),\n",
       " ('forma', 4),\n",
       " ('desse', 4),\n",
       " ('falta', 4),\n",
       " ('vdd', 4),\n",
       " ('também', 4),\n",
       " ('gostar', 4),\n",
       " ('morrendo', 4),\n",
       " ('maceió', 4),\n",
       " ('nublado', 4),\n",
       " ('kkkkk', 4),\n",
       " ('sexta', 4),\n",
       " ('parede', 4),\n",
       " ('todas', 4),\n",
       " ('rain', 4),\n",
       " ('lembrando', 4),\n",
       " ('sonho', 4),\n",
       " ('cheguei', 4),\n",
       " ('kkkk', 4),\n",
       " ('tempestade', 4),\n",
       " ('aos', 4),\n",
       " ('cavalinho', 4),\n",
       " ('gelo', 4),\n",
       " ('dormi', 4),\n",
       " ('baixa', 4),\n",
       " ('nas', 4),\n",
       " ('tendo', 4),\n",
       " ('mto', 4),\n",
       " ('assistindo', 4),\n",
       " ('sério', 4),\n",
       " ('rio', 4),\n",
       " ('felicidade', 4),\n",
       " ('fazendo', 4),\n",
       " ('acabar', 4),\n",
       " ('mano', 4),\n",
       " ('seja', 4),\n",
       " ('pegando', 4),\n",
       " ('acabou', 4),\n",
       " ('jeito', 4),\n",
       " ('acordar', 4),\n",
       " ('cu', 4),\n",
       " ('série', 4),\n",
       " ('sp', 4),\n",
       " ('bike', 4),\n",
       " ('saudade', 4),\n",
       " ('ah', 4),\n",
       " ('setembro', 4),\n",
       " ('capa', 4),\n",
       " ('dela', 4),\n",
       " ('caindo', 4),\n",
       " ('acontece', 4),\n",
       " ('vocês', 4),\n",
       " ('qual', 4),\n",
       " ('dinheiro', 4),\n",
       " ('meus', 4),\n",
       " ('eh', 4),\n",
       " ('agosto', 4),\n",
       " ('fortaleza', 4),\n",
       " ('dá', 4),\n",
       " ('ne', 4),\n",
       " ('moro', 4),\n",
       " ('começa', 4),\n",
       " ('cearense', 4),\n",
       " ('mandar', 4),\n",
       " ('cheirinho', 4),\n",
       " ('seco', 4),\n",
       " ('jardim', 4),\n",
       " ('pantanal', 4),\n",
       " ('saber', 4),\n",
       " ('acaba', 4),\n",
       " ('umidade', 4),\n",
       " ('agradecer', 4),\n",
       " ('moderada', 4),\n",
       " ('ces', 4),\n",
       " ('cantando', 3),\n",
       " ('jovem', 3),\n",
       " ('serviços', 3),\n",
       " ('mostra', 3),\n",
       " ('claro', 3),\n",
       " ('colocar', 3),\n",
       " ('sou', 3),\n",
       " ('inteira', 3),\n",
       " ('ouvindo', 3),\n",
       " ('região', 3),\n",
       " ('motivo', 3),\n",
       " ('usar', 3),\n",
       " ('pronto', 3),\n",
       " ('penso', 3),\n",
       " ('mulher', 3),\n",
       " ('aguento', 3),\n",
       " ('cena', 3),\n",
       " ('raiva', 3),\n",
       " ('foto', 3),\n",
       " ('guardachuva', 3),\n",
       " ('|', 3),\n",
       " ('mormaço', 3),\n",
       " ('posso', 3),\n",
       " ('ler', 3),\n",
       " ('feira', 3),\n",
       " ('fim', 3),\n",
       " ('atenção', 3),\n",
       " ('resolveu', 3),\n",
       " ('máximo', 3),\n",
       " ('tive', 3),\n",
       " ('graças', 3),\n",
       " ('fato', 3),\n",
       " ('estação', 3),\n",
       " ('└pasta', 3),\n",
       " ('arquivo', 3),\n",
       " ('madrugada', 3),\n",
       " ('dele', 3),\n",
       " ('coração', 3),\n",
       " ('comecei', 3),\n",
       " ('arte', 3),\n",
       " ('total', 3),\n",
       " ('obg', 3),\n",
       " ('seria', 3),\n",
       " ('período', 3),\n",
       " ('consigo', 3),\n",
       " ('essas', 3),\n",
       " ('muitas', 3),\n",
       " ('joaoguilherme', 3),\n",
       " ('joaoguilhermestyle', 3),\n",
       " ('joaoejade', 3),\n",
       " ('enaldinho', 3),\n",
       " ('lorenaqueiroz', 3),\n",
       " ('brunamarquezineinspiracao', 3),\n",
       " ('pabllovittar', 3),\n",
       " ('inteiro', 3),\n",
       " ('twitter', 3),\n",
       " ('postando', 3),\n",
       " ('min', 3),\n",
       " ('chuvao', 3),\n",
       " ('pedindo', 3),\n",
       " ('ajude', 3),\n",
       " ('sai', 3),\n",
       " ('vir', 3),\n",
       " ('molharrt', 3),\n",
       " ('filha', 3),\n",
       " ('correndo', 3),\n",
       " ('indo', 3),\n",
       " ('peste', 3),\n",
       " ('ouvir', 3),\n",
       " ('hein', 3),\n",
       " ('pediu', 3),\n",
       " ('esperar', 3),\n",
       " ('contra', 3),\n",
       " ('feito', 3),\n",
       " ('costume', 3),\n",
       " ('pa', 3),\n",
       " ('diferente', 3),\n",
       " ('mãe', 3),\n",
       " ('bora', 3),\n",
       " ('cm', 3),\n",
       " ('ajudar', 3),\n",
       " ('salários', 3),\n",
       " ('ventou', 3),\n",
       " ('voltou', 3),\n",
       " ('mó', 3),\n",
       " ('obra', 3),\n",
       " ('poder', 3),\n",
       " ('expectativa', 3),\n",
       " ('janeiro', 3),\n",
       " ('pedi', 3),\n",
       " ('gritando', 3),\n",
       " ('pedra', 3),\n",
       " ('rola', 3),\n",
       " ('º', 3),\n",
       " ('ventos', 3),\n",
       " ('casaco', 3),\n",
       " ('jogar', 3),\n",
       " ('foram', 3),\n",
       " ('única', 3),\n",
       " ('fogo', 3),\n",
       " ('morei', 3),\n",
       " ('desgraça', 3),\n",
       " ('junto', 3),\n",
       " ('chuvasó', 3),\n",
       " ('nisso', 3),\n",
       " ('friozinho', 3),\n",
       " ('durante', 3),\n",
       " ('kkkkkkk', 3),\n",
       " ('seguinte', 3),\n",
       " ('bipolar', 3),\n",
       " ('existe', 3),\n",
       " ('alguém', 3),\n",
       " ('gotas', 3),\n",
       " ('várias', 3),\n",
       " ('sala', 3),\n",
       " ('trovões', 3),\n",
       " ('lado', 3),\n",
       " ('dificuldade', 3),\n",
       " ('rolou', 3),\n",
       " ('atrás', 3),\n",
       " ('lance', 3),\n",
       " ('pontos', 3),\n",
       " ('vão', 3),\n",
       " ('área', 3),\n",
       " ('cheio', 3),\n",
       " ('problema', 3),\n",
       " ('️', 3),\n",
       " ('além', 3),\n",
       " ('fé', 3),\n",
       " ('brasileiro', 3),\n",
       " ('aparentemente', 3),\n",
       " ('jantar', 3),\n",
       " ('quarentena', 3),\n",
       " ('planos', 3),\n",
       " ('amor', 3),\n",
       " ('roxa', 3),\n",
       " ('ceará', 3),\n",
       " ('pouquinho', 3),\n",
       " ('fala', 3),\n",
       " ('pessoal', 3),\n",
       " ('gota', 3),\n",
       " ('alguns', 3),\n",
       " ('&', 3),\n",
       " ('dizendo', 3),\n",
       " ('venho', 3),\n",
       " ('trabalho', 3),\n",
       " ('perto', 3),\n",
       " ('fdp', 3),\n",
       " ('acordo', 3),\n",
       " ('cuiabámt', 3),\n",
       " ('gelado', 3),\n",
       " ('comigo', 3),\n",
       " ('passou', 3),\n",
       " ('pensa', 3),\n",
       " ('limpinho', 3),\n",
       " ('resolve', 3),\n",
       " ('dança', 3),\n",
       " ('rolar', 3),\n",
       " ('seus', 3),\n",
       " ('deveria', 3),\n",
       " ('dormindo', 3),\n",
       " ('manda', 3),\n",
       " ('levei', 3),\n",
       " ('ananindeua', 3),\n",
       " ('fecha', 3),\n",
       " ('ônibus', 3),\n",
       " ('pedreira', 3),\n",
       " ('cá', 3),\n",
       " ('trinta', 3),\n",
       " ('mão', 3),\n",
       " ('café', 3),\n",
       " ('leve', 3),\n",
       " ('alumiou', 3),\n",
       " ('parou', 3),\n",
       " ('perceber', 2),\n",
       " ('músicas', 2),\n",
       " ('cantou', 2),\n",
       " ('resto', 2),\n",
       " ('serviço', 2),\n",
       " ('outros', 2),\n",
       " ('demora', 2),\n",
       " ('produtos', 2),\n",
       " ('jogaram', 2),\n",
       " ('portão', 2),\n",
       " ('pegou', 2),\n",
       " ('fatos', 2),\n",
       " ('ridículo', 2),\n",
       " ('véi', 2),\n",
       " ('leite', 2),\n",
       " ('setor', 2),\n",
       " ('varal', 2),\n",
       " ('adianta', 2),\n",
       " ('alguma', 2),\n",
       " ('yt', 2),\n",
       " ('fitness', 2),\n",
       " ('mal', 2),\n",
       " ('chovia', 2),\n",
       " ('final', 2),\n",
       " ('tivesse', 2),\n",
       " ('gato', 2),\n",
       " ('trabalhando', 2),\n",
       " ('mo', 2),\n",
       " ('bençãos', 2),\n",
       " ('simplesmente', 2),\n",
       " ('esperança', 2),\n",
       " ('vitória', 2),\n",
       " ('caia', 2),\n",
       " ('tua', 2),\n",
       " ('motoboys', 2),\n",
       " ('pensei', 2),\n",
       " ('achar', 2),\n",
       " ('parei', 2),\n",
       " ('minuto', 2),\n",
       " ('consegui', 2),\n",
       " ('hr', 2),\n",
       " ('pedal', 2),\n",
       " ('velha', 2),\n",
       " ('país', 2),\n",
       " ('vê', 2),\n",
       " ('olhando', 2),\n",
       " ('dona', 2),\n",
       " ('devido', 2),\n",
       " ('segunda', 2),\n",
       " ('errado', 2),\n",
       " ('potencial', 2),\n",
       " ('conhecida', 2),\n",
       " ('anunciação', 2),\n",
       " ('kkkkkkkkkkk', 2),\n",
       " ('conto', 2),\n",
       " ('próximo', 2),\n",
       " ('nevar', 2),\n",
       " ('amanheceu', 2),\n",
       " ('you', 2),\n",
       " ('kkkkkkkkkkkk', 2),\n",
       " ('toró', 2),\n",
       " ('po', 2),\n",
       " ('danado', 2),\n",
       " ('geadas', 2),\n",
       " ('frentes', 2),\n",
       " ('frias', 2),\n",
       " ('acontecendo', 2),\n",
       " ('dita', 2),\n",
       " ('show', 2),\n",
       " ('valeu', 2),\n",
       " ('pena', 2),\n",
       " ('dirá', 2),\n",
       " ('chuvae', 2),\n",
       " ('eita', 2),\n",
       " ('culpa', 2),\n",
       " ('hayden', 2),\n",
       " ('senti', 2),\n",
       " ('chorar', 2),\n",
       " ('dor', 2),\n",
       " ('via', 2),\n",
       " ('chegando', 2),\n",
       " ('fofa', 2),\n",
       " ('pulando', 2),\n",
       " ('sobe', 2),\n",
       " ('imita', 2),\n",
       " ('querendo', 2),\n",
       " ('quarto', 2),\n",
       " ('agitar', 2),\n",
       " ('vegetação', 2),\n",
       " ('contrário', 2),\n",
       " ('animais', 2),\n",
       " ('lar', 2),\n",
       " ('comer', 2),\n",
       " ('pais', 2),\n",
       " ('grande', 2),\n",
       " ('nova', 2),\n",
       " ('chato', 2),\n",
       " ('digo', 2),\n",
       " ('daí', 2),\n",
       " ('segue', 2),\n",
       " ('indiretas', 2),\n",
       " ('bambole', 2),\n",
       " ('temos', 2),\n",
       " ('abre', 2),\n",
       " ('brisa', 2),\n",
       " ('amado', 2),\n",
       " ('disser', 2),\n",
       " ('corre', 2),\n",
       " ('limão', 2),\n",
       " ('portuga', 2),\n",
       " ('partir', 2),\n",
       " ('bailemas', 2),\n",
       " ('insta', 2),\n",
       " ('chuvaquando', 2),\n",
       " ('estavam', 2),\n",
       " ('passando', 2),\n",
       " ('campo', 2),\n",
       " ('receber', 2),\n",
       " ('marco', 2),\n",
       " ('chovechuva', 2),\n",
       " ('máscara', 2),\n",
       " ('óculos', 2),\n",
       " ('chuvasextou', 2),\n",
       " ('subiu', 2),\n",
       " ('usam', 2),\n",
       " ('fechado', 2),\n",
       " ('corona', 2),\n",
       " ('corridinha', 2),\n",
       " ('levou', 2),\n",
       " ('uber', 2),\n",
       " ('garota', 2),\n",
       " ('caí', 2),\n",
       " ('rede', 2),\n",
       " ('virada', 2),\n",
       " ('derrubar', 2),\n",
       " ('levar', 2),\n",
       " ('aprender', 2),\n",
       " ('dançar', 2),\n",
       " ('devoro', 2),\n",
       " ('teu', 2),\n",
       " ('gerais', 2),\n",
       " ('nuvens', 2),\n",
       " ('mesma', 2),\n",
       " ('ajuda', 2),\n",
       " ('time', 2),\n",
       " ('condições', 2),\n",
       " ('criar', 2),\n",
       " ('cachorro', 2),\n",
       " ('peso', 2),\n",
       " ('risco', 2),\n",
       " ('adorei', 2),\n",
       " ('nenhuma', 2),\n",
       " ('abraço', 2),\n",
       " ('serra', 2),\n",
       " ('temporal', 2),\n",
       " ('amanhace', 2),\n",
       " ('neste', 2),\n",
       " ('amar', 2),\n",
       " ('olhos', 2),\n",
       " ('traz', 2),\n",
       " ('transtornos', 2),\n",
       " ('dam', 2),\n",
       " ('interagindocomanotícia', 2),\n",
       " ('credibilidade', 2),\n",
       " ('namoral', 2),\n",
       " ('mta', 2),\n",
       " ('começou', 2),\n",
       " ('horrível', 2),\n",
       " ('virou', 2),\n",
       " ('pecado', 2),\n",
       " ('falar', 2),\n",
       " ('tenha', 2),\n",
       " ('exemplo', 2),\n",
       " ('realmente', 2),\n",
       " ('morando', 2),\n",
       " ('hahahaha', 2),\n",
       " ('caur', 2),\n",
       " ('querer', 2),\n",
       " ('⁰', 2),\n",
       " ('manauara', 2),\n",
       " ('mana', 2),\n",
       " ('fresco', 2),\n",
       " ('linda', 2),\n",
       " ('lavo', 2),\n",
       " ('deixe', 2),\n",
       " ('neymar', 2),\n",
       " ('humilhados', 2),\n",
       " ('ótimo', 2),\n",
       " ('acordei', 2),\n",
       " ('curtir', 2),\n",
       " ('friagem', 2),\n",
       " ('corno', 2),\n",
       " ('pocuo', 2),\n",
       " ('luz', 2),\n",
       " ('amanhece', 2),\n",
       " ('bafo', 2),\n",
       " ('muda', 2),\n",
       " ('lama', 2),\n",
       " ('considerado', 2),\n",
       " ('hiper', 2),\n",
       " ('atípico', 2),\n",
       " ('viagens', 2),\n",
       " ('terreiro', 2),\n",
       " ('candomblecista', 2),\n",
       " ('netflix', 2),\n",
       " ('última', 2),\n",
       " ('lotado', 2),\n",
       " ('aguenta', 2),\n",
       " ('interior', 2),\n",
       " ('meia', 2),\n",
       " ('teremos', 2),\n",
       " ('estrelas', 2),\n",
       " ('cadentes', 2),\n",
       " ('aiaiai', 2),\n",
       " ('delas', 2),\n",
       " ('obrigação', 2),\n",
       " ('colegas', 2),\n",
       " ('veja', 2),\n",
       " ('branca', 2),\n",
       " ('b', 2),\n",
       " ('mimir', 2),\n",
       " ('obrigado', 2),\n",
       " ('outra', 2),\n",
       " ('congelada', 2),\n",
       " ('sistema', 2),\n",
       " ('cagando', 2),\n",
       " ('tentar', 2),\n",
       " ('piso', 2),\n",
       " ('extremamente', 2),\n",
       " ('dezembro', 2),\n",
       " ('março', 2),\n",
       " ('pré', 2),\n",
       " ('inunda', 2),\n",
       " ('bahia', 2),\n",
       " ('passado', 2),\n",
       " ('sombra', 2),\n",
       " ('começando', 2),\n",
       " ('sertão', 2),\n",
       " ('pernambuco', 2),\n",
       " ('matar', 2),\n",
       " ('chuvendo', 2),\n",
       " ('night', 2),\n",
       " ('parte', 2),\n",
       " ('relembrando', 2),\n",
       " ('link', 2),\n",
       " ('perguntando', 2),\n",
       " ('alagamentos', 2),\n",
       " ('deslizamentos', 2),\n",
       " ('bola', 2),\n",
       " ('manutenção', 2),\n",
       " ('chuvajá', 2),\n",
       " ('curto', 2),\n",
       " ('gnt', 2),\n",
       " ('covid', 2),\n",
       " ('algo', 2),\n",
       " ('tempinho', 2),\n",
       " ('sabia', 2),\n",
       " ('juiz', 2),\n",
       " ('caras', 2),\n",
       " ('entra', 2),\n",
       " ('use', 2),\n",
       " ('médico', 2),\n",
       " ('jogadores', 2),\n",
       " ('estádio', 2),\n",
       " ('esquadrão', 2),\n",
       " ('votar', 2),\n",
       " ('bolsonaro', 2),\n",
       " ('desenho', 2),\n",
       " ('preciso', 2),\n",
       " ('certeza', 2),\n",
       " ('abrir', 2),\n",
       " ('story', 2),\n",
       " ('nossa', 2),\n",
       " ('chuvanão', 2),\n",
       " ('sinto', 2),\n",
       " ('cheiro', 2),\n",
       " ('beber', 2),\n",
       " ('acabando', 2),\n",
       " ('resposta', 2),\n",
       " ('engraçado', 2),\n",
       " ('la', 2),\n",
       " ('precisou', 2),\n",
       " ('intenso', 2),\n",
       " ('pede', 2),\n",
       " ('chuvinha', 2),\n",
       " ('chegue', 2),\n",
       " ('resolvo', 2),\n",
       " ('bonito', 2),\n",
       " ('fazenda', 2),\n",
       " ('enchente', 2),\n",
       " ('pau', 2),\n",
       " ('mamãe', 2),\n",
       " ('varanda', 2),\n",
       " ('direito', 2),\n",
       " ('tossindo', 2),\n",
       " ('molhar', 2),\n",
       " ('cadê', 2),\n",
       " ('jurava', 2),\n",
       " ('quentes', 2),\n",
       " ('comprei', 2),\n",
       " ('este', 2),\n",
       " ('semanas', 2),\n",
       " ('insuportável', 2),\n",
       " ('flora', 2),\n",
       " ('vier', 2),\n",
       " ('entender', 2),\n",
       " ('funcionários', 2),\n",
       " ('públicos', 2),\n",
       " ('salário', 2),\n",
       " ('garantido', 2),\n",
       " ('faça', 2),\n",
       " ('palavras', 2),\n",
       " ('diante', 2),\n",
       " ('enquanto', 2),\n",
       " ('neblina', 2),\n",
       " ('contar', 2),\n",
       " ('suficiente', 2),\n",
       " ('assunto', 2),\n",
       " ('aff', 2),\n",
       " ('fumo', 2),\n",
       " ('maconha', 2),\n",
       " ('carnaval', 2),\n",
       " ('califórnia', 2),\n",
       " ('garoa', 2),\n",
       " ('mlk', 2),\n",
       " ('descalço', 2),\n",
       " ('lembrei', 2),\n",
       " ('auge', 2),\n",
       " ('peguei', 2),\n",
       " ('tirando', 2),\n",
       " ('precisamos', 2),\n",
       " ('queimada', 2),\n",
       " ('cuiabno', 2),\n",
       " ('chuvaninguém', 2),\n",
       " ('parada', 2),\n",
       " ('ácida', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = [index for index, frase in enumerate(completo) if 'frio' in frase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(frase, termo):\n",
    "    \n",
    "    tokens = tokenizeTweets(frase)\n",
    "    count=0\n",
    "    for token in tokens:\n",
    "        if token==termo:\n",
    "            count+=1\n",
    "    return count/len(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004524886877828055"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf(completo[ind[0]],'frio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(frases, termo):\n",
    "    count =0 \n",
    "    for frase in frases:\n",
    "        if termo in frase:\n",
    "            count+=1\n",
    "    idf = np.log(len(frases)/count)\n",
    "    return idf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0222831278398874"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(completo, 'frio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12388191279795742"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(completo, 'chuva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeVetor(tweets):\n",
    "    \n",
    "    tokens =[]\n",
    "    for tweet in tweets:\n",
    "        tokens.append(tweet.split())\n",
    "    return tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = tokenizeVetor(completo)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['se',\n",
       "  'você',\n",
       "  'perceber',\n",
       "  'os',\n",
       "  'jurados',\n",
       "  'todos',\n",
       "  'estão',\n",
       "  'cantando',\n",
       "  'músicas',\n",
       "  'em',\n",
       "  'português',\n",
       "  'e',\n",
       "  'no',\n",
       "  'primeiro',\n",
       "  'dia',\n",
       "  'o',\n",
       "  'jarbas',\n",
       "  'tbm',\n",
       "  'cantou',\n",
       "  'o',\n",
       "  'cantando',\n",
       "  'na',\n",
       "  'chuva',\n",
       "  'na',\n",
       "  'versão',\n",
       "  'brasileira',\n",
       "  'então',\n",
       "  'está',\n",
       "  'muito',\n",
       "  'mais',\n",
       "  'para',\n",
       "  'um',\n",
       "  'reflexo',\n",
       "  'sobre',\n",
       "  'como',\n",
       "  'é',\n",
       "  'o',\n",
       "  'público',\n",
       "  'jovem',\n",
       "  'de',\n",
       "  'musicais',\n",
       "  'que',\n",
       "  'acha',\n",
       "  'que',\n",
       "  'apenas',\n",
       "  'em',\n",
       "  'inglês',\n",
       "  'is',\n",
       "  'good'],\n",
       " ['tudo',\n",
       "  'que',\n",
       "  'eu',\n",
       "  'queria',\n",
       "  'agora',\n",
       "  'era',\n",
       "  'uma',\n",
       "  'chuva',\n",
       "  'beeeeeeeemmmmm',\n",
       "  'forte',\n",
       "  'pelo',\n",
       "  'resto',\n",
       "  'da',\n",
       "  'noite']]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TF-IDF\n",
      "cantando    0.345556\n",
      "o           0.190507\n",
      "jarbas      0.183254\n",
      "inglês      0.183254\n",
      "brasileira  0.183254\n",
      "português   0.183254\n",
      "reflexo     0.183254\n",
      "good        0.183254\n",
      "versão      0.183254\n",
      "is          0.183254\n",
      "jurados     0.183254\n",
      "musicais    0.183254\n",
      "músicas     0.172778\n",
      "cantou      0.172778\n",
      "perceber    0.172778\n",
      "jovem       0.165345\n",
      "público     0.159579\n",
      "primeiro    0.159579\n",
      "apenas      0.154868\n",
      "acha        0.150885\n",
      "tbm         0.150885\n",
      "na          0.149614\n",
      "estão       0.147435\n",
      "em          0.146963\n",
      "todos       0.141670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#vectorizer = TfidfVectorizer()\n",
    "\n",
    "def identidade(texto):\n",
    "    return texto\n",
    "\n",
    "vectorizer=TfidfVectorizer(tokenizer=identidade, lowercase = False)\n",
    "tfIdf = vectorizer.fit_transform(teste)\n",
    "df_tfidf = pd.DataFrame(tfIdf[0].T.todense(), index=vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df_tfidf = df_tfidf.sort_values('TF-IDF', ascending=False)\n",
    "print (df_tfidf.head(25)) \n",
    "#print(vectorizer.get_feature_names())\n",
    "tfIdfVetor = tfIdf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_limpo['relevancia'].astype(bool).values\n",
    "rel_centroid = tfIdfVetor[mask].mean(axis=0)\n",
    "irrel_centroid = tfIdfVetor[~mask].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x2990 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['nova', 'frase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&lt',\n",
       " '//',\n",
       " 'a',\n",
       " 'abafado/calor',\n",
       " 'abaixo',\n",
       " 'abandono',\n",
       " 'abandonou',\n",
       " 'abastecer',\n",
       " 'abdominal',\n",
       " 'abelhas',\n",
       " 'abençoar',\n",
       " 'aberta',\n",
       " 'abismos',\n",
       " 'abortinho',\n",
       " 'abraça',\n",
       " 'abraçaram',\n",
       " 'abraço',\n",
       " 'abre',\n",
       " 'abrem',\n",
       " 'abriga',\n",
       " 'abril',\n",
       " 'abrir',\n",
       " 'absurdo',\n",
       " 'abundância',\n",
       " 'acaba',\n",
       " 'acabado',\n",
       " 'acabando',\n",
       " 'acabar',\n",
       " 'acabasse',\n",
       " 'acabei',\n",
       " 'acabou',\n",
       " 'academia',\n",
       " 'aceite',\n",
       " 'aceito',\n",
       " 'acenderam',\n",
       " 'acentuam',\n",
       " 'acervo',\n",
       " 'acha',\n",
       " 'achando',\n",
       " 'achar',\n",
       " 'achei',\n",
       " 'acho',\n",
       " 'achou',\n",
       " 'acima',\n",
       " 'acinzentado',\n",
       " 'acnh',\n",
       " 'acompanhada',\n",
       " 'acompanho',\n",
       " 'acontece',\n",
       " 'acontecendo',\n",
       " 'acontecer',\n",
       " 'aconteceria',\n",
       " 'aconteceu',\n",
       " 'acontecido',\n",
       " 'acordada',\n",
       " 'acordar',\n",
       " 'acordei',\n",
       " 'acordo',\n",
       " 'acordou',\n",
       " 'acostumado',\n",
       " 'acredita',\n",
       " 'acreditar',\n",
       " 'acreditei',\n",
       " 'acréscimos',\n",
       " 'adesivo',\n",
       " 'adiado',\n",
       " 'adianta',\n",
       " 'adivinhando',\n",
       " 'adorei',\n",
       " 'af',\n",
       " 'afeta',\n",
       " 'aff',\n",
       " 'afim',\n",
       " 'afinal',\n",
       " 'aflita',\n",
       " 'afunda',\n",
       " 'agarrada',\n",
       " 'agarradinha',\n",
       " 'agasalho',\n",
       " 'agitar',\n",
       " 'aglomerando',\n",
       " 'aglomerar',\n",
       " 'agonia',\n",
       " 'agora',\n",
       " 'agosto',\n",
       " 'agr',\n",
       " 'agradar',\n",
       " 'agradecem',\n",
       " 'agradecer',\n",
       " 'agradeço',\n",
       " 'agreste',\n",
       " 'agricultores',\n",
       " 'aguardando',\n",
       " 'aguardo',\n",
       " 'aguenta',\n",
       " 'aguentando',\n",
       " 'aguento',\n",
       " 'ah',\n",
       " 'ahahahhahhahhh',\n",
       " 'aham',\n",
       " 'ai',\n",
       " 'aiaiai',\n",
       " 'ainda',\n",
       " 'aitu',\n",
       " 'ajeitando',\n",
       " 'ajuda',\n",
       " 'ajudar',\n",
       " 'ajude',\n",
       " 'ajudo',\n",
       " 'alaga',\n",
       " 'alagado',\n",
       " 'alagamentos',\n",
       " 'alagou',\n",
       " 'alan',\n",
       " 'aleatório',\n",
       " 'aleatórios',\n",
       " 'alegre',\n",
       " 'alegria',\n",
       " 'alergia',\n",
       " 'alesp',\n",
       " 'algm',\n",
       " 'algo',\n",
       " 'algum',\n",
       " 'alguma',\n",
       " 'alguns',\n",
       " 'alguém',\n",
       " 'alimentação',\n",
       " 'aliás',\n",
       " 'allblackcc',\n",
       " 'almejo',\n",
       " 'alonso',\n",
       " 'alto',\n",
       " 'alucinando',\n",
       " 'alumiou',\n",
       " 'alvirrubro',\n",
       " 'alycia',\n",
       " 'além',\n",
       " 'alí',\n",
       " 'alívio',\n",
       " 'amado',\n",
       " 'amamos',\n",
       " 'amanhace',\n",
       " 'amanhece',\n",
       " 'amanheceu',\n",
       " 'amanheci',\n",
       " 'amanhã',\n",
       " 'amantes',\n",
       " 'amar',\n",
       " 'amarrk',\n",
       " 'amazon',\n",
       " 'amazônico',\n",
       " 'ambas',\n",
       " 'ambientado',\n",
       " 'ambos',\n",
       " 'ameaça',\n",
       " 'ameaçando',\n",
       " 'amena',\n",
       " 'amenizar',\n",
       " 'ameno',\n",
       " 'amg',\n",
       " 'amiga',\n",
       " 'amigo',\n",
       " 'amigos',\n",
       " 'amigos&gt',\n",
       " 'amnh',\n",
       " 'amo',\n",
       " 'amoo',\n",
       " 'amor',\n",
       " 'amostrar',\n",
       " 'amou',\n",
       " 'amém',\n",
       " 'amô',\n",
       " 'ananindeua',\n",
       " 'anda',\n",
       " 'andando',\n",
       " 'andar',\n",
       " 'andavam',\n",
       " 'angustiada',\n",
       " 'animado',\n",
       " 'animais',\n",
       " 'animal',\n",
       " 'animalcrossing',\n",
       " 'animação',\n",
       " 'anjo',\n",
       " 'anjos',\n",
       " 'ano',\n",
       " 'anoitece',\n",
       " 'anos',\n",
       " 'anotar',\n",
       " 'antes',\n",
       " 'antigamente',\n",
       " 'antigos',\n",
       " 'antártida',\n",
       " 'anualmente',\n",
       " 'anuncia',\n",
       " 'anunciação',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aparece',\n",
       " 'apareceu',\n",
       " 'aparentemente',\n",
       " 'apareça',\n",
       " 'aparti',\n",
       " 'aparência',\n",
       " 'apenas',\n",
       " 'apesar',\n",
       " 'aprende',\n",
       " 'aprender',\n",
       " 'aproveita',\n",
       " 'aproveitando',\n",
       " 'apuros',\n",
       " 'após',\n",
       " 'aq',\n",
       " 'aquece',\n",
       " 'aquecer',\n",
       " 'aquela',\n",
       " 'aquele',\n",
       " 'aqui',\n",
       " 'ar',\n",
       " 'aracruz',\n",
       " 'armei',\n",
       " 'armo',\n",
       " 'aromas',\n",
       " 'arquivo',\n",
       " 'arranhando',\n",
       " 'arriando',\n",
       " 'arriscar',\n",
       " 'arroz',\n",
       " 'arruda',\n",
       " 'arte',\n",
       " 'artigo',\n",
       " 'ar”',\n",
       " 'as',\n",
       " 'asiático',\n",
       " 'asoro',\n",
       " 'assaltado',\n",
       " 'assim',\n",
       " 'assiste',\n",
       " 'assisti',\n",
       " 'assistindo',\n",
       " 'assistir',\n",
       " 'assistiu',\n",
       " 'assisto',\n",
       " 'assunto',\n",
       " 'assusta',\n",
       " 'astrofísica',\n",
       " 'atacar',\n",
       " 'ate',\n",
       " 'atende',\n",
       " 'atender',\n",
       " 'atentos',\n",
       " 'atenção',\n",
       " 'atoa',\n",
       " 'atrair',\n",
       " 'atrapalham',\n",
       " 'atrapalhando',\n",
       " 'atraso',\n",
       " 'atravessar',\n",
       " 'atração',\n",
       " 'atropelar',\n",
       " 'atrás',\n",
       " 'atualizado',\n",
       " 'atualização',\n",
       " 'até',\n",
       " 'atípico',\n",
       " 'auge',\n",
       " 'aula',\n",
       " 'aulas',\n",
       " 'aumentam',\n",
       " 'aumentar',\n",
       " 'aumentou',\n",
       " 'avanteregatas',\n",
       " 'avisou',\n",
       " 'azul',\n",
       " 'azulejos',\n",
       " 'ação',\n",
       " 'aí',\n",
       " 'b',\n",
       " 'baba',\n",
       " 'baboseiras',\n",
       " 'babyyyy',\n",
       " 'bafo',\n",
       " 'bagulho',\n",
       " 'bahea',\n",
       " 'bahia',\n",
       " 'bailemas',\n",
       " 'bairro',\n",
       " 'baixa',\n",
       " 'baixada',\n",
       " 'baixando',\n",
       " 'baixo',\n",
       " 'balão',\n",
       " 'bambole',\n",
       " 'banho',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'barraco',\n",
       " 'barreira',\n",
       " 'barril',\n",
       " 'barulhinho',\n",
       " 'barulho',\n",
       " 'base',\n",
       " 'basta',\n",
       " 'bastasse',\n",
       " 'bate',\n",
       " 'bateria',\n",
       " 'bbmp',\n",
       " 'be',\n",
       " 'beber',\n",
       " 'bebê',\n",
       " 'beeeeeeeemmmmm',\n",
       " 'beijar',\n",
       " 'beije',\n",
       " 'beijo',\n",
       " 'bela',\n",
       " 'belas',\n",
       " 'beleza',\n",
       " 'belos',\n",
       " 'belém',\n",
       " 'bem',\n",
       " 'benefícios',\n",
       " 'bençãos',\n",
       " 'bestas',\n",
       " 'bestinho',\n",
       " 'beyblade',\n",
       " 'beyoncé',\n",
       " 'biblioteca',\n",
       " 'bicho',\n",
       " 'bicicleta',\n",
       " 'bicycle',\n",
       " 'biito',\n",
       " 'bike',\n",
       " 'bipolar',\n",
       " 'bipolaridade',\n",
       " 'biquíni',\n",
       " 'bitch',\n",
       " 'black',\n",
       " 'block',\n",
       " 'blá',\n",
       " 'boa',\n",
       " 'boas',\n",
       " 'boatos',\n",
       " 'bobo',\n",
       " 'bocas',\n",
       " 'boia',\n",
       " 'bola',\n",
       " 'bolaaaaaaaaa',\n",
       " 'bolinho',\n",
       " 'bolinhos',\n",
       " 'bolsa',\n",
       " 'bolsonaro',\n",
       " 'bom',\n",
       " 'bomba',\n",
       " 'bomo',\n",
       " 'bonita',\n",
       " 'bonito',\n",
       " 'bora',\n",
       " 'borrachas',\n",
       " 'botando',\n",
       " 'botar',\n",
       " 'botei',\n",
       " 'boy',\n",
       " 'bozo',\n",
       " 'br',\n",
       " 'braba',\n",
       " 'branca',\n",
       " 'brasil',\n",
       " 'brasileira',\n",
       " 'brasileiro',\n",
       " 'brasilienses',\n",
       " 'brazil',\n",
       " 'brejaa',\n",
       " 'brejas',\n",
       " 'brigar',\n",
       " 'brilhante',\n",
       " 'brincadeirinha',\n",
       " 'brisa',\n",
       " 'brota',\n",
       " 'brunamarquezineinspiracao',\n",
       " 'bruno',\n",
       " 'brusco',\n",
       " 'bsb',\n",
       " 'bueiro',\n",
       " 'bungee',\n",
       " 'burro',\n",
       " 'buscando',\n",
       " 'buscar',\n",
       " 'bába',\n",
       " 'bênçãos',\n",
       " 'c',\n",
       " 'cabelinhos',\n",
       " 'cabelo',\n",
       " 'cabelos',\n",
       " 'cabeça',\n",
       " 'cachorrinha',\n",
       " 'cachorro',\n",
       " 'cada',\n",
       " 'cadente',\n",
       " 'cadentes',\n",
       " 'cadju',\n",
       " 'cadê',\n",
       " 'cafezinho',\n",
       " 'café',\n",
       " 'cagado',\n",
       " 'cagando',\n",
       " 'cai',\n",
       " 'caia',\n",
       " 'caicó',\n",
       " 'caindo',\n",
       " 'caindoe',\n",
       " 'caio',\n",
       " 'cair',\n",
       " 'caiu',\n",
       " 'caixa',\n",
       " 'caixinha',\n",
       " 'caju',\n",
       " 'caju”',\n",
       " 'cajá',\n",
       " 'califórnia',\n",
       " 'calor',\n",
       " 'calçada…',\n",
       " 'calçadinha',\n",
       " 'calçado',\n",
       " 'cama',\n",
       " 'camilla',\n",
       " 'caminho',\n",
       " 'caminhão',\n",
       " 'campina',\n",
       " 'campo',\n",
       " 'canal…',\n",
       " 'cancelar',\n",
       " 'cancelou',\n",
       " 'candidato',\n",
       " 'candomblecista',\n",
       " 'canela',\n",
       " 'cangote',\n",
       " 'cansativa',\n",
       " 'cansaço',\n",
       " 'cantando',\n",
       " 'cantou',\n",
       " 'caos',\n",
       " 'capa',\n",
       " 'capeta',\n",
       " 'capitão',\n",
       " 'capixabas',\n",
       " 'car',\n",
       " 'cara',\n",
       " 'carai',\n",
       " 'caraiiii',\n",
       " 'caralho',\n",
       " 'caralhoooo',\n",
       " 'caras',\n",
       " 'caraí',\n",
       " 'carente',\n",
       " 'carinho',\n",
       " 'carinhos',\n",
       " 'carnaval',\n",
       " 'carneiro',\n",
       " 'caro',\n",
       " 'carona',\n",
       " 'carrefour',\n",
       " 'carrega',\n",
       " 'carregadas',\n",
       " 'carregue',\n",
       " 'carreira',\n",
       " 'carro',\n",
       " 'carros',\n",
       " 'cartas',\n",
       " 'cartolafc',\n",
       " 'cartão',\n",
       " 'carência',\n",
       " 'casa',\n",
       " 'casaco',\n",
       " 'casamento',\n",
       " 'casas',\n",
       " 'caso',\n",
       " 'casos',\n",
       " 'casta',\n",
       " 'castelão',\n",
       " 'castigo',\n",
       " 'caur',\n",
       " 'causa',\n",
       " 'cavalaria',\n",
       " 'cavaleiros”',\n",
       " 'cavalinho',\n",
       " 'caí',\n",
       " 'caído',\n",
       " 'caírem',\n",
       " 'cd',\n",
       " 'cearense',\n",
       " 'ceará',\n",
       " 'cedo',\n",
       " 'cegueta',\n",
       " 'celular',\n",
       " 'cena',\n",
       " 'cenas',\n",
       " 'centavos',\n",
       " 'centro',\n",
       " 'centrooeste',\n",
       " 'certa',\n",
       " 'certeiro',\n",
       " 'certeza',\n",
       " 'certo',\n",
       " 'cervejinha',\n",
       " 'ces',\n",
       " 'cesar',\n",
       " 'cesarramos',\n",
       " 'chama',\n",
       " 'chamada',\n",
       " 'chamar',\n",
       " 'chamou',\n",
       " 'chance',\n",
       " 'chapéu',\n",
       " 'chargistas',\n",
       " 'chata',\n",
       " 'chataaaaaa',\n",
       " 'chateada',\n",
       " 'chato',\n",
       " 'chaves',\n",
       " 'checa',\n",
       " 'chega',\n",
       " 'chegando',\n",
       " 'chegar',\n",
       " 'chegou',\n",
       " 'chegue',\n",
       " 'cheguei',\n",
       " 'cheia',\n",
       " 'cheio',\n",
       " 'cheirin',\n",
       " 'cheirinho',\n",
       " 'cheiro',\n",
       " 'chernobyl',\n",
       " 'chinelo',\n",
       " 'chique',\n",
       " 'chocolate',\n",
       " 'chora',\n",
       " 'chorando',\n",
       " 'chorar',\n",
       " 'chorara',\n",
       " 'choro',\n",
       " 'chova',\n",
       " 'chove',\n",
       " 'chovendo',\n",
       " 'chover',\n",
       " 'chovesse',\n",
       " 'choveu',\n",
       " 'chovia',\n",
       " 'chupo',\n",
       " 'chuta',\n",
       " 'chute',\n",
       " 'chuteira',\n",
       " 'chuv',\n",
       " 'chuva',\n",
       " 'chuva/frio',\n",
       " 'chuvaaaa',\n",
       " 'chuvadon',\n",
       " 'chuvanão',\n",
       " 'chuvaquando',\n",
       " 'chuvarj…',\n",
       " 'chuvas',\n",
       " 'chuvasaudade',\n",
       " 'chuvasó',\n",
       " 'chuva”',\n",
       " 'chuva…',\n",
       " 'chuvendo',\n",
       " 'chuvinha',\n",
       " 'chuviscou',\n",
       " 'chuvosos',\n",
       " 'chuv…',\n",
       " 'chá',\n",
       " 'cházin',\n",
       " 'chão',\n",
       " 'cicatriz',\n",
       " 'cidade',\n",
       " 'cidadão',\n",
       " 'ciente',\n",
       " 'cima',\n",
       " 'cinco',\n",
       " 'cinema',\n",
       " 'ciscam',\n",
       " 'city',\n",
       " 'claro',\n",
       " 'claros',\n",
       " 'cleide',\n",
       " 'cliente',\n",
       " 'clientes',\n",
       " 'clima',\n",
       " 'climinha',\n",
       " 'climática',\n",
       " 'climáticas',\n",
       " 'clipe',\n",
       " 'cm',\n",
       " 'cmg',\n",
       " 'coach',\n",
       " 'coberta',\n",
       " 'cobertas',\n",
       " 'cobertor',\n",
       " 'cobrado',\n",
       " 'cobrar',\n",
       " 'cobre',\n",
       " 'cobriram',\n",
       " 'cob…',\n",
       " 'codiguin',\n",
       " 'coelho',\n",
       " 'coisa',\n",
       " 'coisas',\n",
       " 'colaborador',\n",
       " 'colar',\n",
       " 'colares',\n",
       " 'colatina',\n",
       " 'colchão',\n",
       " 'colegas',\n",
       " 'colher',\n",
       " 'coloca',\n",
       " 'colocar',\n",
       " 'coloco',\n",
       " 'colocou',\n",
       " 'coloquei',\n",
       " 'colou',\n",
       " 'com',\n",
       " 'combate',\n",
       " 'combina',\n",
       " 'combinei',\n",
       " 'combustível',\n",
       " 'come',\n",
       " 'comecei',\n",
       " 'comendo',\n",
       " 'coment',\n",
       " 'comento',\n",
       " 'comentários',\n",
       " 'comer',\n",
       " 'começa',\n",
       " 'começando',\n",
       " 'começar',\n",
       " 'começaram',\n",
       " 'começou',\n",
       " 'comida',\n",
       " 'comigo',\n",
       " 'comigo”',\n",
       " 'como',\n",
       " 'compartilhe',\n",
       " 'compensação',\n",
       " 'completa',\n",
       " 'completar',\n",
       " 'complicated',\n",
       " 'comprar',\n",
       " 'comprei',\n",
       " 'computador',\n",
       " 'comum',\n",
       " 'com…',\n",
       " 'conceito',\n",
       " 'concerta',\n",
       " 'conchinha',\n",
       " 'concluí',\n",
       " 'concurso',\n",
       " 'condicionado',\n",
       " 'condição',\n",
       " 'condições',\n",
       " 'condominio',\n",
       " 'condomínio',\n",
       " 'conectado',\n",
       " 'conferir',\n",
       " 'confundem',\n",
       " 'congela',\n",
       " 'congelada',\n",
       " 'congelandoporto',\n",
       " 'conhecerem',\n",
       " 'conhecida',\n",
       " 'conhecido',\n",
       " 'conheço',\n",
       " 'conquista',\n",
       " 'consegui',\n",
       " 'conseguia',\n",
       " 'conseguindo',\n",
       " 'considerado',\n",
       " 'considerando',\n",
       " 'consigam',\n",
       " 'consigo',\n",
       " 'consiste',\n",
       " 'constante',\n",
       " 'conta',\n",
       " 'contar',\n",
       " 'continuar',\n",
       " 'continue',\n",
       " 'continuo',\n",
       " 'conto',\n",
       " 'contos',\n",
       " 'contra',\n",
       " 'contrariar',\n",
       " 'contratar',\n",
       " 'contratação',\n",
       " 'contrário',\n",
       " 'conversa',\n",
       " 'conversando',\n",
       " 'convidar',\n",
       " 'coordenador',\n",
       " 'coragem',\n",
       " 'coração',\n",
       " 'cores',\n",
       " 'corinthians',\n",
       " 'corno',\n",
       " 'coro',\n",
       " 'corona',\n",
       " 'corpo',\n",
       " 'corre',\n",
       " 'correndo',\n",
       " 'correr',\n",
       " 'corri',\n",
       " 'corridinha',\n",
       " 'corrido',\n",
       " 'cortados',\n",
       " 'costa',\n",
       " 'costas',\n",
       " 'costela',\n",
       " 'costume',\n",
       " 'costume”',\n",
       " 'cota',\n",
       " 'covas',\n",
       " 'covid',\n",
       " 'cptm',\n",
       " 'cranco',\n",
       " 'cratera',\n",
       " 'crbxbra',\n",
       " 'credibilidade',\n",
       " 'creme',\n",
       " 'criança',\n",
       " 'crianças',\n",
       " 'criar',\n",
       " 'crime',\n",
       " 'criminalidade',\n",
       " 'criticar',\n",
       " 'critiquei',\n",
       " 'crl',\n",
       " 'crlh',\n",
       " 'crlho',\n",
       " 'crítica',\n",
       " 'críticas',\n",
       " 'csa',\n",
       " 'ctz',\n",
       " 'cu',\n",
       " 'cuecas',\n",
       " 'cuiaba',\n",
       " 'cuiabanos',\n",
       " 'cuiabno',\n",
       " 'cuiabá',\n",
       " 'cuiabámt',\n",
       " 'cuida',\n",
       " 'cuidado',\n",
       " 'culpa',\n",
       " 'cuns',\n",
       " 'curar',\n",
       " 'curitiba',\n",
       " 'curso',\n",
       " 'curta',\n",
       " 'curti',\n",
       " 'curtir',\n",
       " 'curto',\n",
       " 'custar',\n",
       " 'cá',\n",
       " 'câmera',\n",
       " 'cão',\n",
       " 'cérebro',\n",
       " 'céu',\n",
       " 'córrego',\n",
       " 'c…',\n",
       " 'd',\n",
       " 'da',\n",
       " 'dallas',\n",
       " 'dam',\n",
       " 'danado',\n",
       " 'dancinha',\n",
       " 'dando',\n",
       " 'danificam',\n",
       " 'dança',\n",
       " 'dançando',\n",
       " 'dançar',\n",
       " 'daquela',\n",
       " 'daquele',\n",
       " 'daqueles',\n",
       " 'daqui',\n",
       " 'dar',\n",
       " 'dark',\n",
       " 'dary',\n",
       " 'das',\n",
       " 'date',\n",
       " 'daí',\n",
       " 'dc',\n",
       " 'dcfandome',\n",
       " 'de',\n",
       " 'dear',\n",
       " 'debaixo',\n",
       " 'decentemente',\n",
       " 'decide',\n",
       " 'deezer',\n",
       " 'definido',\n",
       " 'definiu',\n",
       " 'deitada',\n",
       " 'deitadinha',\n",
       " 'deitar',\n",
       " 'deixa',\n",
       " 'deixar',\n",
       " 'deixe',\n",
       " 'deixem',\n",
       " 'deixo',\n",
       " 'deixou',\n",
       " 'dejetos',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'delicia',\n",
       " 'deliciar',\n",
       " 'delícia',\n",
       " 'demais',\n",
       " 'demissão',\n",
       " 'demora',\n",
       " 'demorei',\n",
       " 'demorou',\n",
       " 'dentro',\n",
       " 'departamento',\n",
       " 'depende',\n",
       " 'dependendo',\n",
       " 'depois',\n",
       " 'depressivo',\n",
       " 'depressão',\n",
       " 'der',\n",
       " 'derrame',\n",
       " 'derrete',\n",
       " 'derrubar',\n",
       " 'derrubou',\n",
       " 'desabamento',\n",
       " 'desabando',\n",
       " 'desabou',\n",
       " 'desabrigadas',\n",
       " 'desanimados',\n",
       " 'desastre',\n",
       " 'descalça',\n",
       " 'descalço',\n",
       " 'descartável',\n",
       " 'descer',\n",
       " 'desculpa',\n",
       " 'desculpas',\n",
       " 'desde',\n",
       " 'desejar',\n",
       " 'desempregados',\n",
       " 'desemprego',\n",
       " 'desenho',\n",
       " 'deserto',\n",
       " 'desesperado',\n",
       " 'desgraça',\n",
       " 'desgraçada',\n",
       " 'desistido',\n",
       " 'desliga',\n",
       " 'desligo',\n",
       " 'deslizamentos',\n",
       " 'desnecessária',\n",
       " 'desnecessário',\n",
       " 'desonesto',\n",
       " 'despenca',\n",
       " 'despercebido',\n",
       " 'dessa',\n",
       " 'dessabglh',\n",
       " 'desse',\n",
       " 'desses',\n",
       " 'destes',\n",
       " 'destrói',\n",
       " 'detalhe',\n",
       " 'deteriorará',\n",
       " 'deu',\n",
       " 'deurmilivre',\n",
       " 'deus',\n",
       " 'deve',\n",
       " 'devem',\n",
       " 'deveria',\n",
       " 'devia',\n",
       " 'devido',\n",
       " 'devoraria',\n",
       " 'devoro',\n",
       " 'dez',\n",
       " 'dezembro',\n",
       " 'df',\n",
       " 'dia',\n",
       " 'diaaaa',\n",
       " 'diadema',\n",
       " 'dialogar',\n",
       " 'diante',\n",
       " 'dias',\n",
       " 'diazinho',\n",
       " 'dica',\n",
       " 'did',\n",
       " 'diferente',\n",
       " 'diferentes',\n",
       " 'diferença',\n",
       " 'dificilmente',\n",
       " 'dificimente',\n",
       " 'dificuldade',\n",
       " 'dificultou',\n",
       " 'difícil',\n",
       " 'digno',\n",
       " 'digo',\n",
       " 'dilúvio',\n",
       " 'diminui',\n",
       " 'dinheiro',\n",
       " 'direct',\n",
       " 'direitistas',\n",
       " 'direito',\n",
       " 'dirigir',\n",
       " 'dirá',\n",
       " 'dirás',\n",
       " 'discarado',\n",
       " 'disco',\n",
       " 'discography',\n",
       " 'dislikes',\n",
       " 'disponível',\n",
       " 'disposição',\n",
       " 'disputa',\n",
       " 'disser',\n",
       " 'disseram',\n",
       " 'dita',\n",
       " 'dito',\n",
       " 'diversa',\n",
       " 'diz',\n",
       " 'dizem',\n",
       " 'dizendo',\n",
       " 'dizer',\n",
       " 'dizia',\n",
       " 'diálogo',\n",
       " 'diógenes',\n",
       " 'dms',\n",
       " 'do',\n",
       " 'dobro',\n",
       " 'dodja',\n",
       " 'doente',\n",
       " 'doi',\n",
       " 'doida',\n",
       " 'doido',\n",
       " 'dois',\n",
       " 'domingo',\n",
       " 'domingos',\n",
       " 'dona',\n",
       " 'dono',\n",
       " 'donzelas',\n",
       " 'dor',\n",
       " 'dorme',\n",
       " 'dormi',\n",
       " 'dormindo',\n",
       " 'dormir',\n",
       " 'dormiram',\n",
       " 'dos',\n",
       " 'dou',\n",
       " 'douglas',\n",
       " 'dourada',\n",
       " 'dps',\n",
       " 'drobado',\n",
       " 'droga',\n",
       " 'dropzinn',\n",
       " 'duas',\n",
       " 'durante',\n",
       " 'durmo',\n",
       " 'duro',\n",
       " 'durou',\n",
       " 'duvido',\n",
       " 'dá',\n",
       " 'dó',\n",
       " 'e',\n",
       " 'eae',\n",
       " 'editora',\n",
       " 'efebofilia',\n",
       " 'efeito',\n",
       " 'eh',\n",
       " 'ein',\n",
       " 'eita',\n",
       " 'eixo',\n",
       " 'ela',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'elite',\n",
       " 'elitra',\n",
       " 'elogio',\n",
       " 'em',\n",
       " 'embaixo',\n",
       " 'embaça',\n",
       " 'embaçou',\n",
       " 'embora',\n",
       " 'emendar',\n",
       " 'emmy',\n",
       " 'emocionada',\n",
       " 'empacotada',\n",
       " 'empatar',\n",
       " 'empatinha',\n",
       " 'empob…',\n",
       " 'enaldinho',\n",
       " 'encarar',\n",
       " 'enchente',\n",
       " 'enchentes',\n",
       " 'encher',\n",
       " 'encima',\n",
       " 'encomenda',\n",
       " 'encomendas',\n",
       " 'encontramos',\n",
       " ...]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_limpo['relevancia'].values\n",
    "X = tfIdf.toarray()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.7, stratify = y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03755868544600939"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6655896607431341"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[404, 204],\n",
       "       [  2,   9]])"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07511737089201878"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6752827140549273"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[402, 197],\n",
       "       [  4,  16]])"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_tree = RandomForestClassifier()\n",
    "clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2300469483568075"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7011308562197092"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[385, 164],\n",
       "       [ 21,  49]])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree_scaled = RandomForestClassifier(random_state=7)\n",
    "clf_tree_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_tree_scaled.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2347417840375587"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6978998384491115"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[382, 163],\n",
       "       [ 24,  50]])"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "novasFrases = [['não', 'esta', 'chovendo'],['chove', 'muito'],['gosto', 'de', 'chuva']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = vectorizer.transform(novasFrases)\n",
    "x_valid = x_valid.todense()\n",
    "x_valid_scaled = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2990)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tree.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
